#+TITLE: Beams
# bash scripts for interacting with the metadir projects

* spec
** metadir
# metadir is a set of csv files
# that functions as a plain-text relational database
# metadir/pairs holds csv files value1-value2.csv
# with content value1_uuid,value2_uuid
# metadir/props holds csv files value/index.csv
# with content value_uuid,value
* scripts
** puma
#+begin_src sh :tangle scripts/puma :tangle-mode (identity #o755)
#!/bin/bash

# "a tree cat that executes"
# suggested by @that-other-guy
# at https://stackoverflow.com/questions/70841809/what-should-this-bash-script-be-called

unset concatenate
OPTIND=1

while getopts 'c' opt; do
  case $opt in
    c) concatenate=1 ;;
    ,*) printf "%s\n" "OPTIONS: -c Concatenate files in INPUTPATH before piping to 'eval COMMAND'" >&2
       exit 1
  esac
done
shift "$(( OPTIND - 1 ))"

if [ $# -ne 4 ]; then
  printf 1>&2 "%s\n" "Usage: $0 [-c] INPUTPATH COMMAND OUTPUTDIR OUTPUTNAME

  Pipes files in INPUTPATH to 'eval COMMAND'
  writes output to OUTPUTDIR/files/DATE-OUTPUTNAME
  creates symbolic link at OUTPUTDIR/links/OUTPUTNAME

  OPTIONS:
    -c Concatenate files in INPUTPATH before piping to 'eval COMMAND'

  EXAMPLE:
    $0 \"assets/2001\" \"scripts/cache\" \"../ops/cache\" \"2001\""
  exit 3
fi

inputpath="$1"
cmd="$2"
outputdir="$3"
outputname="$4"

filedir="$outputdir/files"
linkdir="$outputdir/links"

mkdir -p "$filedir" "$linkdir"

starttime=$(date +%Y%m%d-%H%M%S)
outputfile="$filedir/$starttime-$outputname"
outputlink="$linkdir/$outputname"

# sort input files to puma in predictable order

# do not follow symlinks here to avoid file system loops
# do not follow symlinks provided on the command-line as such arguments are hard to build
# to resolve symlinks to asset folders add a trailing backslash to INPUTPATH

# default `find` output is necessary for broad compatibility
# further filtering should happen inside the COMMAND script
# "concat only one argument" forbids -mindepth 1
# "list only folder contents" requires -mindepth 1 to avoid recursion in ./
# "concat all folder contents" requires -mindepth 1 to avoid catting ./
if [[ "$concatenate" -gt 0 ]]; then
  input=$(find "$inputpath" ! -name ".DS_Store" | sort | xargs cat)
else
  input=$(find "$inputpath" ! -name ".DS_Store" | sort)
fi

amount=$(wc -l <<< "$input");
printf 1>&2 "| %s | %s | %s | %s\n" "$inputpath" "$outputdir" "$outputname" "$amount";

eval "$cmd" <<< "$input" > "$outputfile"

rm -f "$outputlink"
ln -s "$(realpath "$outputfile")" "$outputlink"
#+end_src
** lookup
#+begin_src sh :tangle scripts/lookup :tangle-mode (identity #o755)
#!/bin/bash

if [ $# -ne 2 ]; then
  printf 1>&2 "%s\n" "Usage: $0 FILENAME UUID

  Finds a value corresponding to UUID in FILENAME

  EXAMPLE:
    $0 metadir/filepath/index.csv 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704"
  exit 3
fi

filename="$1"
uuid="$2"

# printf 1>&2 "lookup: %s, %s\n" "$filename" "$uuid"
cat "$filename" | grep -o "^$uuid,.*" | sed "s/^$uuid,//" | head -n 1
#+end_src
** escape.awk
#+begin_src awk :tangle scripts/escape.awk

# escape.awk
#
# escapes data for json or metadir

function escape_json(str) {
    gsub(/\\/, "\\\\", str)
    gsub(/"/,  "\\\"", str)
    gsub(/\b/, "\\b",  str)
    gsub(/\f/, "\\f",  str)
    gsub(/\n/, "\\n",  str)
    gsub(/\r/, "\\r",  str)
    gsub(/\t/, "\\t",  str)
    gsub(/\v/, "",  str)

    return "\42" str "\42"
}
{
    printf "%s", escape_json($0)
}
#+end_src
** unescape
#+begin_src sh :tangle scripts/unescape :tangle-mode (identity #o755)
#!/bin/bash
# unescape.awk breaks on "path\\new", interprets "\n"
# cat <&0 | awk -f scripts/unescape.awk
# python breaks and bloats
# cat <&0 | python3 -c 'import json,sys; print(json.loads(sys.stdin.read()))'
# jq corrupts cyrillic characters when locale is not set right
cat <&0 | jq -r
# gojq doesn't make a difference
# cat <&0 | gojq -r
#+end_src
** build-biorg
#+begin_src sh :tangle scripts/build-biorg :tangle-mode (identity #o755)
#!/bin/bash

# TODO replace jq with jawk

usage () {
  printf 1>&2 "%s\n" "Usage: $0 [-c CONFIG] [-d METADIR] [-p PROPS]

  Reads a stream of datum_uuid,datum pairs from stdin
  looks up PROPS in METADIR (all properties in  by default)
  outputs biorg

  OPTIONS:
  -c json file which contains the schema of properties and relations between them
     defaults to \$PWD/metadir.json
  -d folder which contains the index of properties and relations between them
     defaults to \$PWD/metadir
  -p list of all property names as a space-separated string
     defaults to all property names in the CONFIG

  EXAMPLE:
    cat metadir/props/datum/index.csv | cut -c 1-64 | $0 -d metadir -c config.json -p \"hostdate hostname\" > ../ops/index.bi.org"
}

OPTIND=1
while getopts 'd:c:p:' opt; do
  case $opt in
    d) metadir="$OPTARG" ;;
    c) config="$OPTARG" ;;
    p) config_props="$OPTARG" ;;
    ,*) usage
       exit 1
  esac
done
shift "$(( OPTIND - 1 ))"

# get the path to the folder which contains
# the index of properties and relations between them
if [ ! "$metadir" ]; then
    metadir="$PWD/metadir"
fi

# check if metadir exists
if [[ ! -d "$metadir" ]]; then
  printf 1>&2 "No metadir at %s\n" "$metadir"
  exit 3
fi

# get the path to the json file which contains
# the schema of properties and relations between them
if [ ! "$config" ]; then
    config="$PWD/metadir.json"
fi

# check if config exists
if [[ ! -f "$config" ]]; then
  printf 1>&2 "No config at %s\n" "$config"
  exit 3
fi

# get the list of all property names as a space-separated string
if [ ! "$config_props" ]; then
    config_props=$(jq -r 'keys | join(" ")' "$config")
fi

# parse parent, type and dir from json config for each prop here once
read -r -a props <<< "$config_props"
declare -Ag _
for prop in "${props[@]}"; do
    _[$prop,"parent"]=$(jq -r ".$prop.parent" "$config")
    _[$prop,"label"]=$(jq -r ".$prop.label" "$config")
    _[$prop,"type"]=$(jq -r ".$prop.type" "$config")
    _[$prop,"dir"]=$(jq -r ".$prop.dir" "$config")
done
unset props

# locate other scripts
SCRIPTS="${BASH_SOURCE%/*}"
if [[ ! -d "$SCRIPTS" ]]; then SCRIPTS="$PWD"; fi

# TODO support several roots
# find a property that doesn't have a parent, treat as root
# if there are several matching properties, pick the first in alphabetical order
root=$(jq -r 'map_values(select(has("parent") | not)) | keys[0]' "$config")
# if there are no matching properties, exit with an error
if [ ! "$root" ]; then
  printf 1>&2 "No root property in the config %s\n" "$config"
  exit 3
fi

# build_prop PARENT PARENT_UUID PROP
# build_prop "datum" "12401595" "hostname"
# set two variables, ${PROP} and ${PROP}_uuid
# print an org-mode property or section
build_prop () {
    local prop="$1"
    local parent="$2"
    local parent_uuid="$3"

    local prop_uuid

    # when property is root
    # $root_uuid is passed instead of $parent_uuid
    if [ "$prop" == "$root" ]; then
        prop_uuid="$parent_uuid"
    else
        # lookup $prop_uuid associated with $parent_uuid
        local pair="$metadir/pairs/$parent-$prop.csv"
        if [ -f "$pair" ]; then
            prop_uuid=$(bash "$SCRIPTS/lookup" "$pair" "$parent_uuid")
        fi
    fi

    # continue only if $prop_uuid was found
    if [ "$prop_uuid" ]; then

        # set uuid as a global variable
        # that can be accessed after this function returns
        # TODO handle global scope
        # if no $prop_uuid was found,
        # assign an empty string to reset it
        # so the values don't become mixed up
        # between calls to build_prop
        declare -n UUID="${prop}_uuid"
        UUID="$prop_uuid"

        local prop_value

        local prop_type=${_[$prop,"type"]}
        if [ "$prop_type" == "hash" ]; then
            prop_value="$prop_uuid"
        else
            # query config for the name of the folder
            # that has the index file of the property
            local prop_dir=${_[$prop,"dir"]}
            if [ ! "$prop_dir" ] || [ "$prop_dir" == "null" ]; then
                # by default the name of the folder
                # is the same as the property name
                prop_dir="$prop"
            fi

            # lookup the value associated with $prop_uuid
            prop_value=$(bash "$SCRIPTS/lookup" "$metadir/props/$prop_dir/index.csv" "$prop_uuid")

            # if property value is an escaped string, unescape it
            if [ "$prop_type" == "string" ]; then
                prop_value=$(printf "%s" "$prop_value" | bash "$SCRIPTS/unescape")
            fi
        fi

        # query config for the label
        # to use in the org-mode property
        local prop_label=${_[$prop,"label"]}
        if [ ! "$prop_label" ]; then
            # by default the label
            # is the same as the property name
            prop_label="$prop"
        fi

        if [ "$prop" == "$root" ]; then
            # if property is root, print as plain text
            printf "%s\n" "$prop_value"
        elif [ "$prop_type" == "date" ]; then
            # if property value is a date, wrap it in brackets
            # and print as an org-mode property
            printf ":%s: <%s>\n" "$prop_label" "$prop_value"
        else
            # otherwise print as a literal org-mode property
            printf ":%s: %s\n" "$prop_label" "$prop_value"
        fi

    fi
}
export -f build_prop

# build_node STDIN_UUID COUNTER
# build_node "12401595" 1
# print all metadata properties that are
# associated with the root uuid STDIN_UUID
# as a first level org-mode heading
# with a property block and a section
# log counter to stderr
build_node () {
    local stdin_uuid="$1"
    local counter="$2"

    # log counter to stderr
    # with a carriage return to stay on one line
    printf 1>&2 "                build: %-6s parts\r" "$counter"

    # continue only if the requested uuid is in metadir
    local root_uuid
    root_uuid=$(grep -o "$stdin_uuid" "$metadir/props/$root/index.csv")
    if [ ! "$root_uuid" ]; then
        return
    fi

    printf "* .\n"
    printf ":PROPERTIES:\n"

    printf ":UUID: %s\n" "$root_uuid"

    # initialize queue of properties
    read -r -a props <<< "$config_props"

    # associative array
    # to record which properties have been processed
    local -A processed

    # set uuid of root property
    # and set as processed
    local "${root}_uuid"="$root_uuid"
    processed["$root"]=1

    # TODO process queue from the start
    #      to avoid reverse order in output
    # while queue if full
    while (( ${#props[@]} != 0 )); do
        # get the last element of queue
        local prop=${props[-1]}
        # get its parent property
        local parent=${_[$prop,"parent"]}
        if [ ${processed[$prop]} ] || [ ! "$parent" ]; then
            # if processed or has no parent
            # do nothing
            :
        elif [ ${processed[$parent]} ]; then
            # if parent has been processed
            # build property and set as processed
            local parent_uuid="${parent}_uuid"

            build_prop "$prop" "$parent" "${!parent_uuid}"
            processed["$prop"]=1
        else
            # if parent has not been processed
            # add itself and parent to queue
            props=( "$prop" "$parent" "${props[@]}" )
        fi
        # remove from queue
        unset -v 'props[-1]'
    done
    unset props

    printf ":END:\n"

    # print root prop
    build_prop "$root" "" "$root_uuid"

    # unset all ${}_uuid global variables
    # so they don't bleed to the next loop
    read -r -a props <<< "$config_props"
    for prop in "${props[@]}"; do
        unset "${prop}_uuid"
    done
    unset props
}

export -f build_node

counter=0;

if [[ ! -t 0 ]]; then
    # build nodes for all root uuids from stdin
    while read -r line; do
        build_node "$line" "$counter";
        counter=$((counter + 1));
    done
else
    # otherwise build nodes for all root uuids in metadir
    while read -r line; do
        build_node "$line" "$counter";
        counter=$((counter + 1));
    done <<< "$(cat "$metadir/props/$root/index.csv" | cut -c 1-64)"
fi

# output a newline to stderr
# to preserve the last line
# with a counter and a carriage return
printf 1>&2 "\n"
#+end_src
** build-biorg notes
inconsistent corruption bugs accompany build-biorg
some are fixed by mktemp
some are fixed by locale
but some are only fixed by not using parallel
#+begin_src sh
# build_batch () {
#     counter="$1"
#     while read -r line; do
#         build_biorg "$line" "$counter"
#         printf 1>&2 "                build: %-6s parts\r" "$counter"
#     done
# }

# export -f build_batch

# temp=$(mktemp)
# cat <&0 > "$temp"
# printf 1>&2 "%s\n" "$temp"

# causes corruption
# parallel build_biorg {} "{#}"

# causes corruption
# parallel -a "$temp" --pipe-part build_batch "{}" "{#}"

# does not cause corruption
# parallel --pipe build_batch "{}" "{#}"

# does not cause corruption
# while read -r line; do
#     build_biorg "$line" "$counter";
#     counter=$(($counter + 1));
# done
#+end_src

** build-json
#+begin_src sh :tangle scripts/build-json :tangle-mode (identity #o755)
#!/bin/bash

# filepath_uuid,filepath | enrich prop | json with prop

if [ $# -ne 0 ] || [[ -t 0 ]]; then
  printf 1>&2 "%s\n" "Usage: $0

  Reads a stream of filepath-uuid pairs from stdin
  outputs event cache with RULENAME

  EXAMPLE:
    cat metadir/props/filepath/index.csv | $0 > index.json"
  exit 3
fi

build_json () {
    line="$1"
    counter="$2"

    # TODO: read datum_uuid instead
    datum_uuid=$(printf "%s" "$line" | cut -c 1-64)
    datum_escaped=$(printf "%s" "$line" | cut -c 66-)
    datum=$(printf "%s" "$datum_escaped" | jq -r)

    filepath_uuid=$(bash scripts/lookup "metadir/pairs/datum-filepath.csv" "$datum_uuid")
    filepath_escaped=$(bash scripts/lookup "metadir/props/filepath/index.csv" "$filepath_uuid")
    filepath=$(printf "%s" "$filepath_escaped" | jq -r)

    # filesize_uuid=$(bash scripts/lookup "metadir/pairs/filepath-filesize.csv" "$filepath_uuid")
    # filesize=$(bash scripts/lookup "metadir/props/filesize/index.csv" "$filesize_uuid")

    # filetype_uuid=$(bash scripts/lookup "metadir/pairs/filepath-filetype.csv" "$filepath_uuid")
    # filetype_escaped=$(bash scripts/lookup "metadir/props/filetype/index.csv" "$filetype_uuid")
    # filetype=$(printf "%s" "$filetype_escaped" | jq -r)

    # moddate_uuid=$(bash scripts/lookup "metadir/pairs/filepath-moddate.csv" "$filepath_uuid")
    # moddate=$(bash scripts/lookup "metadir/props/date/index.csv" "$moddate_uuid")

    guestname_uuid=$(bash scripts/lookup "metadir/pairs/datum-guestname.csv" "$datum_uuid")
    guestname=$(bash scripts/lookup "metadir/props/name/index.csv" "$guestname_uuid")

    guestdate_uuid=$(bash scripts/lookup "metadir/pairs/datum-guestdate.csv" "$datum_uuid")
    guestdate=$(bash scripts/lookup "metadir/props/date/index.csv" "$guestdate_uuid")

    hostname_uuid=$(bash scripts/lookup "metadir/pairs/datum-hostname.csv" "$datum_uuid")
    hostname=$(bash scripts/lookup "metadir/props/name/index.csv" "$hostname_uuid")

    hostdate_uuid=$(bash scripts/lookup "metadir/pairs/datum-hostdate.csv" "$datum_uuid")
    hostdate=$(bash scripts/lookup "metadir/props/date/index.csv" "$hostdate_uuid")

    event=$(jq -c --arg UUID "$datum_uuid" \
                  --arg FILE_PATH "$filepath" \
                  --arg GUEST_NAME "$guestname" \
                  --arg GUEST_DATE "$gustdate" \
                  --arg HOST_NAME "$hostname" \
                  --arg HOST_DATE "$hostdate" \
                  --arg DATUM "$datum" \
                  '{$UUID,$FILE_PATH,$GUEST_NAME,$GUEST_DATE,$HOST_NAME,$HOST_DATE,$DATUM}' <(printf "[]"))
    printf "%s\n" "$event"
    printf 1>&2 "                build: %-6s parts\r" "$counter"
}

export -f build_json

temp=$(mktemp)
cat <&0 > "$temp"

parallel -a "$temp" build_json {} "{#}"
printf 1>&2 "\n"
#+end_src
** build-json-curves
#+begin_src sh :tangle scripts/build-json-curves :tangle-mode (identity #o755)
#!/bin/bash

# filepath_uuid,filepath | enrich prop | json with prop

if [ $# -ne 0 ] || [[ -t 0 ]]; then
  printf 1>&2 "%s\n" "Usage: $0

  Reads a stream of filepath-uuid pairs from stdin
  outputs event cache with RULENAME

  EXAMPLE:
    cat metadir/props/filepath/index.csv | $0 > index.json"
  exit 3
fi

build_json () {
    line="$1"
    counter="$2"

    datum_uuid=$(printf "%s" "$line" | cut -c 1-64)
    # datum_escaped=$(printf "%s" "$line" | cut -c 66-)
    # datum=$(printf "%s" "$datum_escaped" | awk -f scripts/unescape.awk)

    filepath_uuid=$(bash scripts/lookup "metadir/pairs/datum-filepath.csv" "$datum_uuid")
    filepath_escaped=$(bash scripts/lookup "metadir/props/filepath/index.csv" "$filepath_uuid")
    # filepath=$(printf "%s" "$filepath_escaped" | awk -f scripts/unescape.awk)

    # filesize_uuid=$(bash scripts/lookup "metadir/pairs/filepath-filesize.csv" "$filepath_uuid")
    # filesize=$(bash scripts/lookup "metadir/props/filesize/index.csv" "$filesize_uuid")

    # filetype_uuid=$(bash scripts/lookup "metadir/pairs/filepath-filetype.csv" "$filepath_uuid")
    # filetype_escaped=$(bash scripts/lookup "metadir/props/filetype/index.csv" "$filetype_uuid")
    # filetype=$(printf "%s" "$filetype_escaped" | awk -f scripts/unescape.awk)

    # moddate_uuid=$(bash scripts/lookup "metadir/pairs/filepath-moddate.csv" "$filepath_uuid")
    # moddate=$(bash scripts/lookup "metadir/props/date/index.csv" "$moddate_uuid")

    # guestname_uuid=$(bash scripts/lookup "metadir/pairs/datum-guestname.csv" "$datum_uuid")
    # guestname=$(bash scripts/lookup "metadir/props/name/index.csv" "$guestname_uuid")
    guestname="fetsorn"

    # guestdate_uuid=$(bash scripts/lookup "metadir/pairs/datum-guestdate.csv" "$datum_uuid")
    # if [ "$guestdate_uuid"]; then
    #     guestdate=$(bash scripts/lookup "metadir/props/date/index.csv" "$guestdate_uuid")
    # else
        moddate_uuid=$(bash scripts/lookup "metadir/pairs/filepath-moddate.csv" "$filepath_uuid")
        moddate=$(bash scripts/lookup "metadir/props/date/index.csv" "$moddate_uuid")
        guestdate="$moddate"
    # fi

    # hostname_uuid=$(bash scripts/lookup "metadir/pairs/datum-hostname.csv" "$datum_uuid")
    # hostname=$(bash scripts/lookup "metadir/props/name/index.csv" "$hostname_uuid")
    hostname="fetsorn"

    # hostdate_uuid=$(bash scripts/lookup "metadir/pairs/datum-hostdate.csv" "$datum_uuid")
    # if [ "$hostdate_uuid" ]; then
    #     hostdate=$(bash scripts/lookup "metadir/props/date/index.csv" "$hostdate_uuid")
    # else
        # moddate_uuid=$(bash scripts/lookup "metadir/pairs/filepath-moddate.csv" "$filepath_uuid")
        # moddate=$(bash scripts/lookup "metadir/props/date/index.csv" "$moddate_uuid")
        hostdate="$moddate"
    # fi

    printf '{"UUID": "%s","FILE_PATH": %s,"GUEST_NAME": "%s","GUEST_DATE": "%s","HOST_NAME": "%s","HOST_DATE": "%s"}\n' \
           "$datum_uuid" \
           "$filepath_escaped" \
           "$guestname" \
           "$guestdate" \
           "$hostname" \
           "$hostdate"
    printf 1>&2 "                build: %-6s parts\r" "$counter"
}

# temp=$(mktemp)
# cat <&0 > "$temp"

# parallel -a "$temp" build_json {} "{#}"
parallel build_json {} "{#}"
printf 1>&2 "\n"
#+end_src
** break-fs
#+begin_src sh :tangle scripts/break-fs :tangle-mode (identity #o755)
#!/bin/bash

# list of paths | break-fs | path to a temporary metadir

if [ $# -ne 0 ] || [[ -t 0 ]]; then
  printf 1>&2 "%s\n" "Usage: $0

  Reads a list of filepaths from stdin,
  stats each, outputs path to a temporary metadir

  EXAMPLE:
    find . | $0"
  exit 3
fi

cache_file () {
  filepath="$1"
  counter="$2"

  # skip directories
  if [ -d "$filepath" ]; then return; fi

  temp=$(mktemp -d)

  mkdir -p "$temp/props/filepath" \
           "$temp/props/filetype" \
           "$temp/props/filesize" \
           "$temp/props/date" \
           "$temp/props/datum" \
           "$temp/pairs"

  filepath_trimmed=$(sed 's/^assets\///' <<< "$filepath")
  filepath_uuid=$(sha256sum <<< "$filepath_trimmed" | cut -c 1-64)
  filepath_escaped=$(jq -R <<< "$filepath_trimmed")
  printf '%s,"%s"\n' "$filepath_uuid" "$filepath_escaped" > "$temp/props/filepath/index.csv"

  filesize=$(stat --printf="%s" "$filepath")
  filesize_uuid=$(sha256sum <<< "$filesize" | cut -c 1-64)
  printf "%s,%s\n" "$filesize_uuid" "$filesize" > "$temp/props/filesize/index.csv"
  printf "%s,%s\n" "$filepath_uuid" "$filesize_uuid" > "$temp/pairs/filepath-filesize.csv"

  filetype=$(file -b "$filepath")
  filetype_uuid=$(sha256sum <<< "$filetype" | cut -c 1-64)
  filetype_escaped=$(jq -R <<< "$filetype")
  printf '%s,"%s"\n' "$filetype_uuid" "$filetype_escaped" > "$temp/props/filetype/index.csv"
  printf "%s,%s\n" "$filepath_uuid" "$filetype_uuid" > "$temp/pairs/filepath-filetype.csv"

  moddate=$(stat --printf="%y" "$filepath" | cut -c 1-10)
  moddate_uuid=$(sha256sum <<< "$moddate" | cut -c 1-64)
  printf "%s,%s\n" "$moddate_uuid" "$moddate" > "$temp/props/date/index.csv"
  printf "%s,%s\n" "$filepath_uuid" "$moddate_uuid" > "$temp/pairs/filepath-moddate.csv"

  filehash=$(sha256sum "$filepath" | cut -c 1-64)
  printf "%s,%s\n" "$filepath_uuid" "$filehash" > "$temp/pairs/filepath-filehash.csv"

  # add a datum stub to each asset
  datum_uuid=$(uuidgen | sha256sum | cut -c 1-64)
  printf '%s,""\n' "$datum_uuid" > "$temp/props/datum/index.csv"
  printf '%s,%s\n' "$datum_uuid" "$filepath_uuid" > "$temp/pairs/datum-filepath.csv"

  printf 1>&2 "cache: %s - %s...%s\r" "$counter" "${filepath::30}" "${filepath: -30}"
  printf "%s\n" "$temp"
}

export -f cache_file

tempins=$(parallel cache_file {} "{#}")
printf 1>&2 "\n"

tempout=$(mktemp -d)

mkdir -p "$tempout/props/filepath" \
         "$tempout/props/filetype" \
         "$tempout/props/filesize" \
         "$tempout/props/date" \
         "$tempout/props/datum" \
         "$tempout/pairs"

sed 's/$/\/props\/filepath\/index.csv/'   <<< "$tempins" | xargs cat > "$tempout/props/filepath/index.csv"
sed 's/$/\/props\/filesize\/index.csv/'   <<< "$tempins" | xargs cat > "$tempout/props/filesize/index.csv"
sed 's/$/\/props\/filetype\/index.csv/'   <<< "$tempins" | xargs cat > "$tempout/props/filetype/index.csv"
sed 's/$/\/props\/date\/index.csv/'       <<< "$tempins" | xargs cat > "$tempout/props/date/index.csv"
sed 's/$/\/props\/datum\/index.csv/'      <<< "$tempins" | xargs cat > "$tempout/props/datum/index.csv"
sed 's/$/\/pairs\/filepath-filesize.csv/' <<< "$tempins" | xargs cat > "$tempout/pairs/filepath-filesize.csv"
sed 's/$/\/pairs\/filepath-filetype.csv/' <<< "$tempins" | xargs cat > "$tempout/pairs/filepath-filetype.csv"
sed 's/$/\/pairs\/filepath-moddate.csv/'  <<< "$tempins" | xargs cat > "$tempout/pairs/filepath-moddate.csv"
sed 's/$/\/pairs\/filepath-filehash.csv/' <<< "$tempins" | xargs cat > "$tempout/pairs/filepath-filehash.csv"
sed 's/$/\/pairs\/datum-filepath.csv/'    <<< "$tempins" | xargs cat > "$tempout/pairs/datum-filepath.csv"

xargs rm -r <<< "$tempins"

printf "%s\n" "$tempout"
#+end_src
** break-json
#+begin_src sh :tangle scripts/break-json :tangle-mode (identity #o755)
#!/bin/bash

# list of jsons | break-json | path to a temporary metadir

if [ $# -ne 0 ] || [[ -t 0 ]]; then
    printf 1>&2 "%s\n" "Usage: $0

    Reads a list of json elements from stdin
    breaks each, outputs path to a temporary metadir

    EXAMPLE:
      cat cache.json | $0"
    exit 3
fi

break_json () {

    line="$1"
    counter="$2"

    temp=$(mktemp -d)

    mkdir -p "$temp/props/filepath" \
             "$temp/props/filetype" \
             "$temp/props/filesize" \
             "$temp/props/date" \
             "$temp/props/datum" \
             "$temp/pairs"

    datum_uuid=$(jq -r '.UUID' <<< "$line")
    if [ "$datum_uuid" == "" ]; then
        datum_uuid=$(uuidgen | sha256sum | cut -c 1-64)
    fi
    datum=$(printf "%s" "$line" | jq -r 'if .DATUM then .DATUM else "" end')
    datum_escaped=$(printf "%s\n" "$datum" | jq -R)
    printf '%s,%s\n' "$datum_uuid" "$datum_escaped" > "$temp/props/datum/index.csv"

    filepath=$(jq -r '.FILE_PATH' <<< "$line")
    if [ "$filepath" ]; then

        filepath_uuid=$(printf "%s" "$filepath" | sha256sum | cut -c 1-64)
        filepath_escaped=$(printf "%s" "$filepath" | jq -R)
        printf "%s,%s\n" "$filepath_uuid" "$filepath_escaped" > "$temp/props/filepath/index.csv"
        printf '%s,%s\n' "$datum_uuid" "$filepath_uuid" > "$temp/pairs/datum-filepath.csv"

        filesize=$(jq -r '.SIZE' <<< "$line")
        if [ "$filesize" ]; then
            filesize_uuid=$(printf "%s" "$filesize" | sha256sum | cut -c 1-64)
            printf "%s,%s\n" "$filesize_uuid" "$filesize" > "$temp/props/filesize/index.csv"
            printf "%s,%s\n" "$filepath_uuid" "$filesize_uuid" > "$temp/pairs/filepath-filesize.csv"
        fi

        filetype=$(jq -r '.FILE_TYPE' <<< "$line")
        if [ "$filetype" ]; then
            filetype_uuid=$(printf "%s" "$filetype" | sha256sum | cut -c 1-64)
            filetype_escaped=$(printf "%s" "$filetype" | jq -R)
            printf "%s,%s\n" "$filetype_uuid" "$filetype_escaped" > "$temp/props/filetype/index.csv"
            printf "%s,%s\n" "$filepath_uuid" "$filetype_uuid" > "$temp/pairs/filepath-filetype.csv"
        fi

        moddate=$(jq -r '.MOD_DATE' <<< "$line")
        if [ "$moddate" ]; then
            moddate_uuid=$(printf "%s" "$moddate" | sha256sum | cut -c 1-64)
            printf "%s,%s\n" "$moddate_uuid" "$moddate" > "$temp/props/date/index.csv"
            printf "%s,%s\n" "$filepath_uuid" "$moddate_uuid" > "$temp/pairs/filepath-moddate.csv"
        fi

        filehash=$(jq -r '.HASH' <<< "$line")
        if [ "$filehash" ]; then
            printf "%s,%s\n" "$filepath_uuid" "$filehash" > "$temp/pairs/filepath-filehash.csv"
        fi
    fi

    printf 1>&2 "break: %s - %s\r" "$counter" "$temp"
    printf "%s\n" "$temp"
}

export -f break_json

tempins=$(parallel break_json {} "{#}")
printf 1>&2 "\n"

tempout=$(mktemp -d)

mkdir -p "$tempout/props/filepath" \
         "$tempout/props/filetype" \
         "$tempout/props/filesize" \
         "$tempout/props/date" \
         "$tempout/props/datum" \
         "$tempout/pairs"

sed 's/$/\/props\/filepath\/index.csv/'   <<< "$tempins" | xargs cat > "$tempout/props/filepath/index.csv"
sed 's/$/\/props\/filesize\/index.csv/'   <<< "$tempins" | xargs cat > "$tempout/props/filesize/index.csv"
sed 's/$/\/props\/filetype\/index.csv/'   <<< "$tempins" | xargs cat > "$tempout/props/filetype/index.csv"
sed 's/$/\/props\/date\/index.csv/'       <<< "$tempins" | xargs cat > "$tempout/props/date/index.csv"
sed 's/$/\/props\/datum\/index.csv/'      <<< "$tempins" | xargs cat > "$tempout/props/datum/index.csv"
sed 's/$/\/pairs\/filepath-filesize.csv/' <<< "$tempins" | xargs cat > "$tempout/pairs/filepath-filesize.csv"
sed 's/$/\/pairs\/filepath-filetype.csv/' <<< "$tempins" | xargs cat > "$tempout/pairs/filepath-filetype.csv"
sed 's/$/\/pairs\/filepath-moddate.csv/'  <<< "$tempins" | xargs cat > "$tempout/pairs/filepath-moddate.csv"
sed 's/$/\/pairs\/filepath-filehash.csv/' <<< "$tempins" | xargs cat > "$tempout/pairs/filepath-filehash.csv"
sed 's/$/\/pairs\/datum-filepath.csv/'    <<< "$tempins" | xargs cat > "$tempout/pairs/datum-filepath.csv"

xargs rm -r <<< "$tempins"

printf "%s\n" "$tempout"
#+end_src
** break-biorg.awk
#+begin_src awk :tangle scripts/break-biorg.awk :noweb tangle

# break-biorg.awk
# MIT License Copyright (c) 2022 Anton Davydov
#
# Reads a biorg compilation,
# breaks each node, outputs path to a temporary metadir

# json is parsed with jawk
# MIT License Copyright (c) 2020 Mohamed Akram

<<jawk>>

function escape_json(str) {
    gsub(/\\/, "\\\\", str)
    gsub(/"/,  "\\\"", str)
    gsub(/\b/, "\\b",  str)
    gsub(/\f/, "\\f",  str)
    gsub(/\n/, "\\n",  str)
    gsub(/\r/, "\\r",  str)
    gsub(/\t/, "\\t",  str)
    gsub(/\v/, "",  str)

    return "\42" str "\42"
}
function set_uuid(prop,       prop_value_bash, prop_uuid) {

    if (parsed[prop] == 0) { return }
    prop_value_bash = values[prop]
    if (_[prop,"type"] == "string") {
        # string can contain arbitrary characters
        # so it is wrapped in single quotes when passed to bash pipes
        # escape the single quotes inside the raw string here
        gsub("'", "'\"'\"'", prop_value_bash);
    };

    if (prop == config_root) {
        # TODO does root uuid have to be hardcoded?
        prop_uuid = values["uuid"];
        # if no prop_uuid is provided, generate unique uuid
        if (prop_uuid == "") {
            prop_uuid_cmd = "uuidgen | sha256sum | cut -c 1-64";
            prop_uuid_cmd | getline prop_uuid_new;
            prop_uuid = prop_uuid_new;
            close(prop_uuid_cmd);
        }
    } else if (_[prop,"type"] == "hash") {
        prop_uuid = values[prop];
    } else {
        prop_uuid_cmd = "printf '%s' '" prop_value_bash "' | sha256sum | cut -c 1-64";
        prop_uuid_cmd | getline prop_uuid_new;
        prop_uuid = prop_uuid_new;
        close(prop_uuid_cmd);
    }
    uuids[prop]=prop_uuid;
}
function write_prop(prop, parent, parent_uuid,       prop_value_escaped, prop_dir, prop_index, prop_pair) {

    if (parsed[prop] == 0) { return }
    prop_value_escaped = values[prop];
    if (_[prop,"type"] == "string") {
        # strip trailing newlines
        # to avoid unexpected stripping later
        gsub(/\n*$/, "", prop_value_escaped);
        # escape as a json string
        prop_value_escaped = escape_json(prop_value_escaped);
    };

    if (_[prop,"type"] != "hash") {
        prop_dir = _[prop,"dir"]
        if (prop_dir == "") { prop_dir = prop }
        system("mkdir -p " temp "/props/" prop_dir)
        # write prop_uuid,prop_value to metadir/props/${prop_dir}/index.csv
        prop_index = temp "/props/" prop_dir "/index.csv";
        printf "%s,%s\n", uuids[prop], prop_value_escaped >> prop_index;
    }

    if (prop != config_root) {
        system("mkdir -p " temp "/pairs")
        # write parent_uuid,prop_uuid to metadir/pairs/datum-guestname.csv
        prop_pair = temp "/pairs/" parent "-" prop ".csv";
        printf "%s,%s\n", parent_uuid, uuids[prop] >> prop_pair;
    }
}
function write_node() {

    # get a list of props from config
    # if parent is processed, write_prop
    # otherwise push to queue

    queue=split(config_props, props)

    # set uuid for root and consider it processed
    # but do not write yet
    set_uuid(config_root)
    processed[config_root] = 1

    while (queue > 0) {
        prop = props[queue]
        parent = _[prop,"parent"]
        if (processed[prop] == 1) {
            delete props[queue]
            queue--
        } else if (processed[parent] == 1) {
            set_uuid(prop)
            write_prop(prop, parent, uuids[parent])
            processed[prop] = 1
            delete props[queue]
            queue--
        } else {
            queue++
            props[queue]=parent
        }
    }
    # write root prop
    write_prop(config_root, "", "")
}
BEGIN {
    temp_cmd = "mktemp -d"
    temp_cmd | getline temp;

    # init jawk
    JSON="\1";
    TYPE="\2";
    __KEYS="\3";
    __jawk__init();

    # TODO fallback CONFIG to pwd
    if (CONFIG == "") {
        print "No config provided" > "/dev/stderr"
        exit 1
    }
    # use jawk to parse json into an associative array _
    # to get value of key2 of object key1 call _["key1","key2"]
    __parse_json(CONFIG)

    # TODO rewrite to use the jawk array
    config_props_cmd = "jq -r 'keys | join(\" \")' " CONFIG
    config_props_cmd | getline config_props;

    # TODO rewrite to use the jawk array
    root_cmd = "jq -r 'map_values(select(has(\"parent\") | not)) | keys[0]' " CONFIG
    root_cmd | getline config_root;

    counter=0;
}
# heading line
/^\* \.$/ {
    afterheading=1
    # write previous node
    if (node==1) {
        values[config_root]=datum
        parsed[config_root]=1;
        write_node();
    }
    # remember to write node on the next heading
    node=1;
    # print the number of processed nodes
    counter++;
    printf "%s\r", counter >> "/dev/stderr";
    # delete previous node's props and datum
    delete values;
    delete uuids;
    delete parsed;
    delete processed;
    datum="";
    next;
}
# remember to parse lines as properties
# while inside the property block
/^:PROPERTIES:/ {
    if (afterheading==1) {
        property_block=1; next;
    }
    afterheading=0;
}
/^:END:/ {
    afterheading=0;
    property_block=0; next;
}
/^:/ {
    afterheading=0;
    if (property_block==1) {
        line=$0;
        gsub("^:", "", line);
        st = index(line,":");
        prop_label = substr(line,1,st-1);
        prop_value = substr(line,st+1);

        # TODO does UUID have to be hardcoded?
        if (prop_label == "UUID") {
            prop = "uuid"
        } else {
            # TODO handle if config doesn't have a label
            # TODO rewrite to use the jawk array
            split(config_props, props)
            for (p in props) {
                p_label = _[props[p],"label"]
                if (p_label == prop_label) {
                    prop = props[p]
                    break
                }
            }
            # label_cmd = "jq -r 'map_values(select(.label == \"" prop_label "\")) | keys[0]' "  CONFIG
            # label_cmd | getline prop_new;
            # prop = prop_new
            # close(label_cmd)
        }

        # trim whitespace
        gsub("^[ \t]+", "", prop_value);
        gsub("[ \t]+$", "", prop_value);
        # trim brackets from timestamps
        if (_[prop,"type"] == "date") {
            gsub(/^</, "", prop_value);
            gsub(/>$/, "", prop_value);
        };
        values[prop]=prop_value;
        # keep track of existing props manually
        # because checking the value
        # returns an empty string
        # and so is not reliable
        parsed[prop]=1;
        next;
    }
}
{
    afterheading=0
    datum=datum $0 RS;
}
END {
    # write last node
    if (node==1) {
        values[config_root]=datum
        parsed[config_root]=1;
        write_node();
    }
    printf "%s\n", temp;
}
#+end_src

** jawk.awk
#+NAME: jawk
#+begin_src awk

function __parse_json(configpath) {
    ESCAPE="(\\\\[^u[:cntrl:]]|\\\\u[0-9a-fA-F]{4})"
    CHAR="[^[:cntrl:]\"\\\\]"
    STRING="\"" CHAR "*(" ESCAPE CHAR "*)*\""
    NUMBER="-?(0|[1-9][0-9]*)([.][0-9]*)?([eE][+-]?[0-9]*)?"
    KEYWORD="null|false|true"
    JAWKREGEX= STRING "|" NUMBER "|" KEYWORD "|[][{}:,]"

    config_cmd = "grep -E -o '" JAWKREGEX "' " configpath
    __json_length=0
    while ((config_cmd | getline config_line) > 0) {
        __json_lines[__json_length]=config_line
        __json_length++
    }
    # TODO handle if parsing of malformed json never exits
    __json_queue=0
    __parse_value(__json_lines[__json_queue])
}
function __jawk__init(i) {
    __CHAR[0] = "\0"
    __CHAR[1] = "\1"
    __CHAR[2] = "\2"
    __CHAR[3] = "\3"
    __CHAR[4] = "\4"
    __CHAR[5] = "\5"
    __CHAR[6] = "\6"
    __CHAR[7] = "\7"
    __CHAR[8] = "\10"
    __CHAR[9] = "\11"
    __CHAR[10] = "\12"
    __CHAR[11] = "\13"
    __CHAR[12] = "\14"
    __CHAR[13] = "\15"
    __CHAR[14] = "\16"
    __CHAR[15] = "\17"
    __CHAR[16] = "\20"
    __CHAR[17] = "\21"
    __CHAR[18] = "\22"
    __CHAR[19] = "\23"
    __CHAR[20] = "\24"
    __CHAR[21] = "\25"
    __CHAR[22] = "\26"
    __CHAR[23] = "\27"
    __CHAR[24] = "\30"
    __CHAR[25] = "\31"
    __CHAR[26] = "\32"
    __CHAR[27] = "\33"
    __CHAR[28] = "\34"
    __CHAR[29] = "\35"
    __CHAR[30] = "\36"
    __CHAR[31] = "\37"
    __CHAR[32] = "\40"
    __CHAR[33] = "\41"
    __CHAR[34] = "\42"
    __CHAR[35] = "\43"
    __CHAR[36] = "\44"
    __CHAR[37] = "\45"
    __CHAR[38] = "\46"
    __CHAR[39] = "\47"
    __CHAR[40] = "\50"
    __CHAR[41] = "\51"
    __CHAR[42] = "\52"
    __CHAR[43] = "\53"
    __CHAR[44] = "\54"
    __CHAR[45] = "\55"
    __CHAR[46] = "\56"
    __CHAR[47] = "\57"
    __CHAR[48] = "\60"
    __CHAR[49] = "\61"
    __CHAR[50] = "\62"
    __CHAR[51] = "\63"
    __CHAR[52] = "\64"
    __CHAR[53] = "\65"
    __CHAR[54] = "\66"
    __CHAR[55] = "\67"
    __CHAR[56] = "\70"
    __CHAR[57] = "\71"
    __CHAR[58] = "\72"
    __CHAR[59] = "\73"
    __CHAR[60] = "\74"
    __CHAR[61] = "\75"
    __CHAR[62] = "\76"
    __CHAR[63] = "\77"
    __CHAR[64] = "\100"
    __CHAR[65] = "\101"
    __CHAR[66] = "\102"
    __CHAR[67] = "\103"
    __CHAR[68] = "\104"
    __CHAR[69] = "\105"
    __CHAR[70] = "\106"
    __CHAR[71] = "\107"
    __CHAR[72] = "\110"
    __CHAR[73] = "\111"
    __CHAR[74] = "\112"
    __CHAR[75] = "\113"
    __CHAR[76] = "\114"
    __CHAR[77] = "\115"
    __CHAR[78] = "\116"
    __CHAR[79] = "\117"
    __CHAR[80] = "\120"
    __CHAR[81] = "\121"
    __CHAR[82] = "\122"
    __CHAR[83] = "\123"
    __CHAR[84] = "\124"
    __CHAR[85] = "\125"
    __CHAR[86] = "\126"
    __CHAR[87] = "\127"
    __CHAR[88] = "\130"
    __CHAR[89] = "\131"
    __CHAR[90] = "\132"
    __CHAR[91] = "\133"
    __CHAR[92] = "\134"
    __CHAR[93] = "\135"
    __CHAR[94] = "\136"
    __CHAR[95] = "\137"
    __CHAR[96] = "\140"
    __CHAR[97] = "\141"
    __CHAR[98] = "\142"
    __CHAR[99] = "\143"
    __CHAR[100] = "\144"
    __CHAR[101] = "\145"
    __CHAR[102] = "\146"
    __CHAR[103] = "\147"
    __CHAR[104] = "\150"
    __CHAR[105] = "\151"
    __CHAR[106] = "\152"
    __CHAR[107] = "\153"
    __CHAR[108] = "\154"
    __CHAR[109] = "\155"
    __CHAR[110] = "\156"
    __CHAR[111] = "\157"
    __CHAR[112] = "\160"
    __CHAR[113] = "\161"
    __CHAR[114] = "\162"
    __CHAR[115] = "\163"
    __CHAR[116] = "\164"
    __CHAR[117] = "\165"
    __CHAR[118] = "\166"
    __CHAR[119] = "\167"
    __CHAR[120] = "\170"
    __CHAR[121] = "\171"
    __CHAR[122] = "\172"
    __CHAR[123] = "\173"
    __CHAR[124] = "\174"
    __CHAR[125] = "\175"
    __CHAR[126] = "\176"
    __CHAR[127] = "\177"
    __CHAR[128] = "\200"
    __CHAR[129] = "\201"
    __CHAR[130] = "\202"
    __CHAR[131] = "\203"
    __CHAR[132] = "\204"
    __CHAR[133] = "\205"
    __CHAR[134] = "\206"
    __CHAR[135] = "\207"
    __CHAR[136] = "\210"
    __CHAR[137] = "\211"
    __CHAR[138] = "\212"
    __CHAR[139] = "\213"
    __CHAR[140] = "\214"
    __CHAR[141] = "\215"
    __CHAR[142] = "\216"
    __CHAR[143] = "\217"
    __CHAR[144] = "\220"
    __CHAR[145] = "\221"
    __CHAR[146] = "\222"
    __CHAR[147] = "\223"
    __CHAR[148] = "\224"
    __CHAR[149] = "\225"
    __CHAR[150] = "\226"
    __CHAR[151] = "\227"
    __CHAR[152] = "\230"
    __CHAR[153] = "\231"
    __CHAR[154] = "\232"
    __CHAR[155] = "\233"
    __CHAR[156] = "\234"
    __CHAR[157] = "\235"
    __CHAR[158] = "\236"
    __CHAR[159] = "\237"
    __CHAR[160] = "\240"
    __CHAR[161] = "\241"
    __CHAR[162] = "\242"
    __CHAR[163] = "\243"
    __CHAR[164] = "\244"
    __CHAR[165] = "\245"
    __CHAR[166] = "\246"
    __CHAR[167] = "\247"
    __CHAR[168] = "\250"
    __CHAR[169] = "\251"
    __CHAR[170] = "\252"
    __CHAR[171] = "\253"
    __CHAR[172] = "\254"
    __CHAR[173] = "\255"
    __CHAR[174] = "\256"
    __CHAR[175] = "\257"
    __CHAR[176] = "\260"
    __CHAR[177] = "\261"
    __CHAR[178] = "\262"
    __CHAR[179] = "\263"
    __CHAR[180] = "\264"
    __CHAR[181] = "\265"
    __CHAR[182] = "\266"
    __CHAR[183] = "\267"
    __CHAR[184] = "\270"
    __CHAR[185] = "\271"
    __CHAR[186] = "\272"
    __CHAR[187] = "\273"
    __CHAR[188] = "\274"
    __CHAR[189] = "\275"
    __CHAR[190] = "\276"
    __CHAR[191] = "\277"
    __CHAR[192] = "\300"
    __CHAR[193] = "\301"
    __CHAR[194] = "\302"
    __CHAR[195] = "\303"
    __CHAR[196] = "\304"
    __CHAR[197] = "\305"
    __CHAR[198] = "\306"
    __CHAR[199] = "\307"
    __CHAR[200] = "\310"
    __CHAR[201] = "\311"
    __CHAR[202] = "\312"
    __CHAR[203] = "\313"
    __CHAR[204] = "\314"
    __CHAR[205] = "\315"
    __CHAR[206] = "\316"
    __CHAR[207] = "\317"
    __CHAR[208] = "\320"
    __CHAR[209] = "\321"
    __CHAR[210] = "\322"
    __CHAR[211] = "\323"
    __CHAR[212] = "\324"
    __CHAR[213] = "\325"
    __CHAR[214] = "\326"
    __CHAR[215] = "\327"
    __CHAR[216] = "\330"
    __CHAR[217] = "\331"
    __CHAR[218] = "\332"
    __CHAR[219] = "\333"
    __CHAR[220] = "\334"
    __CHAR[221] = "\335"
    __CHAR[222] = "\336"
    __CHAR[223] = "\337"
    __CHAR[224] = "\340"
    __CHAR[225] = "\341"
    __CHAR[226] = "\342"
    __CHAR[227] = "\343"
    __CHAR[228] = "\344"
    __CHAR[229] = "\345"
    __CHAR[230] = "\346"
    __CHAR[231] = "\347"
    __CHAR[232] = "\350"
    __CHAR[233] = "\351"
    __CHAR[234] = "\352"
    __CHAR[235] = "\353"
    __CHAR[236] = "\354"
    __CHAR[237] = "\355"
    __CHAR[238] = "\356"
    __CHAR[239] = "\357"
    __CHAR[240] = "\360"
    __CHAR[241] = "\361"
    __CHAR[242] = "\362"
    __CHAR[243] = "\363"
    __CHAR[244] = "\364"
    __CHAR[245] = "\365"
    __CHAR[246] = "\366"
    __CHAR[247] = "\367"
    __CHAR[248] = "\370"
    __CHAR[249] = "\371"
    __CHAR[250] = "\372"
    __CHAR[251] = "\373"
    __CHAR[252] = "\374"
    __CHAR[253] = "\375"
    __CHAR[254] = "\376"
    __CHAR[255] = "\377"

    __UNESCAPE["\\b"] = "\b"
    __UNESCAPE["\\f"] = "\f"
    __UNESCAPE["\\n"] = "\n"
    __UNESCAPE["\\r"] = "\r"
    __UNESCAPE["\\t"] = "\t"
    __UNESCAPE["\\\""] = "\""
    __UNESCAPE["\\\\"] = "\\"
    __UNESCAPE["\\/"] = "/"

    for (i = 0; i < 256; i++)
        __HEX[sprintf("%02X", i)] = i
}

function __utf8enc(c) {

    # 0x007f
    if (c <= 127) {
        return __CHAR[c]
    # 0x07ff
    } else if (c <= 2047) {
        # 110xxxxx 10xxxxxx
        return __CHAR[192 + int(c/64)] __CHAR[128 + (c%64)]
    # 0xffff
    } else if (c <= 65535) {
        # 1110xxxx 10xxxxxx 10xxxxxx
        return __CHAR[224 + int(c/4096)] \
            __CHAR[128 + (int(c/64) % 64)] \
            __CHAR[128 + (c%64)]
    # 0x10ffff
    } else if (c <= 1114111) {
        # 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
        return __CHAR[240 + int(c/262144)] \
            __CHAR[128 + (int(c/4096) % 64)] \
            __CHAR[128 + (int(c/64) % 64)] \
            __CHAR[128 + (c%64)]
    }
}

function __hextodec(h) {
    h = toupper(h)
    return 256 * __HEX[substr(h, 1, 2)] + __HEX[substr(h, 3)]
}

function __unescape(s, i, s2, c, u, h) {
    i = match(s, /\\([bfnrt"\\\/]|u[0-9a-fA-F]{4})/)
    if (!i) return s
    s2 = ""
    while (i) {
        c = substr(s, RSTART, RLENGTH)
        if (c in __UNESCAPE) u = __UNESCAPE[c]
        else {
            h = __hextodec(substr(c, 3))
            # high surrogate pair
            # 0xd800 - 0xdbff
            if (h >= 55296 && h <= 56319) {
                c = substr(s, RSTART + RLENGTH, 6)
                RLENGTH += 6
                h = 65536 + ((h - 55296) * 1024) + \
                    (__hextodec(substr(c, 3)) - 56320)
            }
            u = __utf8enc(h)
        }
        s2 = s2 substr(s, 1, RSTART - 1) u
        s = substr(s, RSTART + RLENGTH)
        i = match(s, /\\([bfnrt"\\\/]|u[0-9a-fA-F]{4})/)
    }
    s2 = s2 s
    return s2
}

function keys(a, o, n, i) {
    # differentiate between the root object and an empty root key
    # if the root object
    if (o == "" && o == 0) {
        # if object
        if ((__KEYS,"length") in _) {
            n = _[__KEYS,"length"]
            while (++i <= n) a[_[__KEYS,i]] = _[__KEYS,i]
        # if array
        } else {
            n = _["length"]
            while (++i <= _["length"]) a[i] = i
        }
    }
    else {
        # if object
        if ((o,__KEYS,"length") in _) {
            n = _[o,__KEYS,"length"]
            while (++i <= n) a[_[o,__KEYS,i]] = o SUBSEP _[o,__KEYS,i]
        # if array
        } else {
            n = _[o,"length"]
            while (++i <= n) a[i] = o SUBSEP i
        }
    }
    return n
}

function __parse_array(path, i, sep, raw_value, value) {
    i = 0
    sep = ""
    raw_value = "["
    while (sep != "]") {
        __json_queue++
        value=__json_lines[__json_queue]
        if (value == "]") {
            raw_value = raw_value value
            break
        }
        value = __parse_value(value, __getpath(path, ++i))
        __json_queue++
        sep=__json_lines[__json_queue]
        raw_value = raw_value value sep
    }
    _[__getpath(path, "length")] = i
    return raw_value
}

function __parse_value(value, path, raw_value, start, type) {
    start = substr(value, 1, 1)
    if (start == "{") {
        _[path] = path
        type = "object"
        raw_value = __parse_object(path)
    } else if (start == "[") {
        _[path] = path
        type = "array"
        raw_value = __parse_array(path)
    } else {
        raw_value = value
        if (start == "\"") {
            # remove surrounding quotes
            value = __unescape(substr(value, 2, length(value) - 2))
            type = "string"
        }
        else if (value == "true") {
            value = 1
            type = "boolean"
        }
        else if (value == "false") {
            value = 0
            type = "boolean"
        }
        else if (value == "null") {
            value = ""
            type = "null"
        } else {
            type = "number"
        }
        if (path == "" && path == 0)
            _[0] = value
        else
            _[path] = value
    }
    _[__getpath(path, JSON)] = raw_value
    _[__getpath(path, TYPE)] = type
    return raw_value
}

function __getpath(path, key) {
    # differentiate between the root object and an empty root key
    return path == "" && path == 0 ? key : path SUBSEP key
}

function __parse_object(path, sep, i, raw_value, key, colon, value, raw_key) {
    sep = ""
    i = 0
    raw_value = "{"
    while (sep != "}") {
        __json_queue++
        key=__json_lines[__json_queue]
        if (key == "}") {
            raw_value = raw_value key
            break
        }
        __json_queue++
        colon=__json_lines[__json_queue]
        __json_queue++
        value=__json_lines[__json_queue]
        raw_key = key
        key = substr(key, 2, length(key) - 2)
        value = __parse_value(value, __getpath(path, key))
        __json_queue++
        sep=__json_lines[__json_queue]
        raw_value = raw_value raw_key colon value sep
        ++i
        _[__getpath(path, __KEYS SUBSEP i)] = key
    }
    _[__getpath(path, __KEYS SUBSEP "length")] = i
    return raw_value
}
#+end_src
** break-biorg
could be faster than serial break-biorg.awk, but isn't
#+begin_src sh
#!/bin/bash
usage () {
    printf 1>&2 "%s\n" "Usage: $0 [-c CONFIG] BIORG

    Breaks down BIORG,
    outputs path to a temporary metadir

  OPTIONS:
  -c json file which contains the schema of properties and relations between them
     defaults to \$PWD/metadir.json

    EXAMPLE:
      cat cache.json | $0"
}

OPTIND=1
while getopts 'c:' opt; do
  case $opt in
    c) config="$OPTARG" ;;
    ,*) usage
       exit 1
  esac
done
shift "$(( OPTIND - 1 ))"

if [ $# -ne 1 ]; then
    usage
    exit 3
fi

biorg="$1"

# get the path to the json file which contains
# the schema of properties and relations between them
if [ ! "$config" ]; then
    config="$PWD/metadir.json"
fi

# check if config exists
if [[ ! -f "$config" ]]; then
  printf 1>&2 "No config at %s\n" "$config"
  exit 3
fi

# locate other scripts
SCRIPTS="${BASH_SOURCE%/*}"
if [[ ! -d "$SCRIPTS" ]]; then SCRIPTS="$PWD"; fi

# TODO support several roots
# find a property that doesn't have a parent, treat as root
# if there are several matching properties, pick the first in alphabetical order
root=$(jq -r 'map_values(select(has("parent") | not)) | keys[0]' "$config")
# if there are no matching properties, exit with an error
if [ ! "$root" ]; then
  printf 1>&2 "No root property in the config %s\n" "$config"
  exit 3
fi

# get the list of all property names as a space-separated string
config_props=$(jq -r 'keys | join(" ")' "$config")

break_biorg () {
    local config="$1"
    local scripts="$2"
    local counter="$3"

    local temp
    temp=$(awk -f "$scripts/break-biorg.awk" -v CONFIG="$config" <&0)
    printf "%s\n" "$temp"

    printf 1>&2 "     break: %s parts - %s\r" "$counter" "$temp"
}

export -f break_biorg

tempins=$(parallel -a "$biorg" --pipe-part --recstart "* .\n" --recend "\n" break_biorg  "$config" "$SCRIPTS" "{#}")
printf 1>&2 "\n"

tempout=$(mktemp -d)

read -r -a props <<< "$config_props"
mkdir -p "$tempout/pairs"
for prop in "${props[@]}"; do
    prop_type=$(jq -r ".$prop.type" "$config")
    # hash has no index
    if [ "$prop_type" != "hash" ]; then
        prop_dir=$(jq -r ".$prop.dir" "$config")
        if [ ! "$prop_dir" ] || [ "$prop_dir" == "null" ]; then
            prop_dir="$prop"
        fi
        # skip if directory was already created and processed
        if [ ! -d "$tempout/props/$prop_dir" ]; then
            mkdir -p "$tempout/props/$prop_dir"
            while read -r tempin; do
                # suppress stderr in case file is not found in tempin
                sed "s/$/\/props\/$prop_dir\/index.csv/" <<< "$tempin" | xargs cat 2> /dev/null | sort | uniq >> "$tempout/props/$prop_dir/index.csv"
            done <<< "$tempins"
        fi
    fi
    # TODO support recursive root
    # root has no pair
    if [ "$prop" != "$root" ]; then
        parent=$(jq -r ".$prop.parent" "$config")
        # update pair
        while read -r tempin; do
            # suppress stderr in case file is not found in tempin
            sed "s/$/\/pairs\/$parent-$prop.csv/" <<< "$tempin" | xargs cat 2> /dev/null | sort | uniq >> "$tempout/pairs/$parent-$prop.csv"
        done <<< "$tempins"
    fi
done

xargs rm -r <<< "$tempins"

printf "%s\n" "$tempout"
#+end_src
** gc
#+begin_src sh :tangle scripts/gc :tangle-mode (identity #o755)
#!/bin/bash

usage () {
  printf 1>&2 "%s\n" "Usage: $0 [-c CONFIG] [-d METADIR]

  Deduplicates, sorts,
  and removes garbage from METADIR

  EXAMPLE:
    $0"
}

OPTIND=1
while getopts 'c:d:' opt; do
  case $opt in
    c) config="$OPTARG" ;;
    d) metadir="$OPTARG" ;;
    ,*) usage
       exit 1
  esac
done
shift "$(( OPTIND - 1 ))"

# get the path to the folder which contains
# the index of properties and relations between them
if [ ! "$metadir" ]; then
    metadir="$PWD/metadir"
fi

# check if metadir exists
if [[ ! -d "$metadir" ]]; then
  printf 1>&2 "No metadir at %s\n" "$metadir"
  exit 3
fi

# get the path to the json file which contains
# the schema of properties and relations between them
if [ ! "$config" ]; then
    config="$PWD/metadir.json"
fi

# check if config exists
if [[ ! -f "$config" ]]; then
  printf 1>&2 "No config at %s\n" "$config"
  exit 3
fi

# TODO support several roots
# find a property that doesn't have a parent, treat as root
# if there are several matching properties, pick the first in alphabetical order
root=$(jq -r 'map_values(select(has("parent") | not)) | keys[0]' "$config")
# if there are no matching properties, exit with an error
if [ ! "$root" ]; then
  printf 1>&2 "No root property in the config %s\n" "$config"
  exit 3
fi

# get the list of all property names as a space-separated string
config_props=$(jq -r 'keys | join(" ")' "$config")

# usage: gc CSVFILE RGFILE
# Removes from CSVFILE all keys which are not in RGFILE
_gc () {
    csvfile="$1"
    rgpattern="$2"

    printf 1>&2 "gc: %s\n" "$csvfile"

    # hangs if csvfile is empty
    if [ -s "$csvfile" ]; then
        cat "$csvfile" | rg -f <(printf "%s" "$rgpattern") | sort | uniq | sort -t "," -k 2 -k 1 | sponge "$csvfile"
    fi
}

export -f _gc

read -r -a props <<< "$config_props"

declare -Ag _
for prop in "${props[@]}"; do
    _[$prop,"parent"]=$(jq -r ".$prop.parent" "$config")
    _[$prop,"type"]=$(jq -r ".$prop.type" "$config")
    _[$prop,"dir"]=$(jq -r ".$prop.dir" "$config")
done

declare -A processed

# deduplicate and sort root prop
root_index="$metadir/props/$root/index.csv"
if [ -f "$root_index" ]; then
    _gc "$root_index" ".*"
fi
processed["$root"]=1

while (( ${#props[@]} != 0 )); do
    # get the last element of queue
    prop=${props[-1]}
    # get its parent property
    parent=${_[$prop,"parent"]}
    if [ ${processed[$prop]} ] || [ ! "$parent" ]; then
        # if processed or has no parent
        # remove from queue
        unset -v 'props[-1]'
    elif [ ${processed[$parent]} ]; then

        parent_props="$metadir/props/$parent/index.csv"
        if [ -f "$parent_props" ]; then
            parent_uuids=$(cat "$parent_props" | cut -c 1-64)

            prop_pair="$metadir/pairs/$parent-$prop.csv"
            if [ -f "$prop_pair" ]; then
                _gc "$prop_pair" "$parent_uuids"
            fi
        fi

        prop_type=$(jq -r ".$prop.type" "$config")
        if [ "$prop_type" != "hash" ]; then

            parent_pair="$metadir/pairs/$parent-$prop.csv"
            if [ -f "$parent_pair" ]; then
                prop_uuids=$(cat "$parent_pair" | cut -c 66-)

                prop_dir=$(jq -r ".$prop.dir" "$config")
                if [ ! "$prop_dir" ] || [ "$prop_dir" == "null" ]; then
                    prop_dir="$prop"
                fi

                prop_index="$metadir/props/$prop_dir/index.csv"
                if [ -f "$prop_index" ]; then
                    _gc "$prop_index" "$prop_uuids"
                fi
            fi

        fi
        processed["$prop"]=1
        # remove from queue
        unset -v 'props[-1]'
    else
        # remove from queue
        unset -v 'props[-1]'
        # if parent has not been processed
        # add itself and parent to queue
        props=( "${props[@]}" "$prop" "$parent" )
    fi
done

#+end_src
** merge
#+begin_src sh :tangle scripts/merge :tangle-mode (identity #o755)
#!/bin/bash

usage () {
  printf 1>&2 "%s\n" "Usage: $0 NEW MAIN [-c CONFIG]

  Merges NEW metadir into MAIN

  OPTIONS:
  -c json file which contains the schema of properties and relations between them
     defaults to \$PWD/metadir.json

  EXAMPLE:
    $0 \"../ops/inbox\" \"./metadir\" > index.json"
}

OPTIND=1
while getopts 'c:' opt; do
  case $opt in
    c) config="$OPTARG" ;;
    ,*) usage
       exit 1
  esac
done
shift "$(( OPTIND - 1 ))"

if [ $# -ne 2 ]; then
  usage
  exit 3
fi

new="$1"
main="$2"

# get the path to the json file which contains
# the schema of properties and relations between them
if [ ! "$config" ]; then
    config="$PWD/metadir.json"
fi

# check if config exists
if [[ ! -f "$config" ]]; then
  printf 1>&2 "No config at %s\n" "$config"
  exit 3
fi

# TODO support several roots
# find a property that doesn't have a parent, treat as root
# if there are several matching properties, pick the first in alphabetical order
root=$(jq -r 'map_values(select(has("parent") | not)) | keys[0]' "$config")
# if there are no matching properties, exit with an error
if [ ! "$root" ]; then
  printf 1>&2 "No root property in the config %s\n" "$config"
  exit 3
fi

# get the list of all property names as a space-separated string
config_props=$(jq -r 'keys | join(" ")' "$config")

# remove changed entries from main
# and only then append changed entries from new
update_file () {
    csvpath="$1"

    # printf 1>&2 "update: %s\n" "$csvpath"
    if [ -f "$new/$csvpath" ]; then
        changed_lines=$(mktemp)
        if [ -f "$main/$csvpath" ]; then
            comm -23 <(cat "$new/$csvpath" | sort | uniq) <(cat "$main/$csvpath" | sort) > "$changed_lines"
        else
            cp "$new/$csvpath" "$changed_lines"
        fi
        # cmd > mktemp and then <(cat | cmd) replaces <(printf $(cmd) | cmd)
        # to fix an inconsistent bug that corrupts multibyte characters
        # other times bug is fixed by setting the right locale
        changed_uuids=$(mktemp)
        cat "$changed_lines" | cut -c 1-64 > "$changed_uuids"
        # use grep because ripgrep bugs out on an empty pattern file
        # https://github.com/BurntSushi/ripgrep/issues/1332
        unchanged_lines=$(mktemp)
        cat "$main/$csvpath" 2>/dev/null | grep -vf "$changed_uuids" > "$unchanged_lines"
        # remove empty newline in case unchanged_lines is empty
        mkdir -p "$main/$(dirname "$csvpath")"
        cat "$unchanged_lines" <(cat "$changed_lines" | sort | uniq) 2>/dev/null | sed '/^$/d' > "$main/$csvpath"
    else
        # printf 1>&2 "skip %s\n" "$csvpath"
        :
    fi
}

export -f update_file

read -r -a props <<< "$config_props"
for prop in "${props[@]}"; do
    prop_type=$(jq -r ".$prop.type" "$config")
    # hash has no index
    if [ "$prop_type" != "hash" ]; then
        prop_dir=$(jq -r ".$prop.dir" "$config")
        if [ ! "$prop_dir" ] || [ "$prop_dir" == "null" ]; then
            prop_dir="$prop"
        fi
        # update index
        update_file "props/$prop_dir/index.csv"
    fi
    # TODO support recursive root
    # root has no pair
    if [ "$prop" != "$root" ]; then
        parent=$(jq -r ".$prop.parent" "$config")
        # update pair
        update_file "pairs/$parent-$prop.csv"
    fi
done
#+end_src
** merge-one
#+begin_src sh :tangle scripts/merge-one :tangle-mode (identity #o755)
#!/bin/bash

if [ $# -ne 3 ]; then
  printf 1>&2 "%s\n" "Usage: $0 NEW MAIN UUID

  Merges UUID from NEW metadir into MAIN

  EXAMPLE:
    $0 \"../ops/inbox\" \"./metadir\" > index.json"
  exit 3
fi

new="$1"
main="$2"
uuid="$3"

append_file () {
    new="$1"
    main="$2"
    uuid="$3"
    csvpath="$4"

    printf 1>&2 "append: %s\n" "$csvpath"
    if [ -f "$new/$csvpath" ]; then
        comm -13 <(cat "$main/$csvpath" | grep "$uuid") <(cat "$new/$csvpath" | grep "$uuid") >> "$main/$csvpath"
    else
        printf 1>&2 "skip %s\n" "$csvpath"
    fi
}

export -f append_file

update_file () {
    new="$1"
    main="$2"
    uuid="$3"
    csvpath="$4"

    printf 1>&2 "update: %s\n" "$csvpath"
    if [ -f "$new/$csvpath" ]; then
        changed_uuids=$(mktemp)
        cat "$new/$csvpath" | grep "$uuid" | cut -c 1-64 > "$changed_uuids"
        # use grep because ripgrep bugs out on an empty pattern file
        # https://github.com/BurntSushi/ripgrep/issues/1332
        unchanged_lines=$(mktemp)
        cat "$main/$csvpath" | grep -vf "$changed_uuids" > "$unchanged_lines"
        # remove empty newline in case unchanged_lines is empty
        cat "$unchanged_lines" <(cat "$new/$csvpath" | grep "$uuid") | sed '/^$/d' > "$main/$csvpath"
    else
        printf 1>&2 "skip %s\n" "$csvpath"
    fi
}

export -f update_file

# pairs cannot be appended as is
# because changed entries would conflict with the old
# instead, remove changed entries from main
# and only then append changed entries from new
update_file "$new" "$main" "$uuid" "props/datum/index.csv"
update_file "$new" "$main" "$uuid" "pairs/datum-filepath.csv"
update_file "$new" "$main" "$uuid" "pairs/datum-guestdate.csv"
update_file "$new" "$main" "$uuid" "pairs/datum-guestname.csv"
update_file "$new" "$main" "$uuid" "pairs/datum-hostdate.csv"
update_file "$new" "$main" "$uuid" "pairs/datum-hostname.csv"
update_file "$new" "$main" "$uuid" "pairs/datum-privacy.csv"
update_file "$new" "$main" "$uuid" "pairs/datum-tag.csv"
update_file "$new" "$main" "$uuid" "pairs/filepath-filesize.csv"
update_file "$new" "$main" "$uuid" "pairs/filepath-filetype.csv"
update_file "$new" "$main" "$uuid" "pairs/filepath-moddate.csv"
update_file "$new" "$main" "$uuid" "pairs/filepath-filehash.csv"

# the rest is content-addressable so can be appended and garbage collected later
# but update is faster than garbage collection
update_file "$new" "$main" "$uuid" "props/date/index.csv"
update_file "$new" "$main" "$uuid" "props/name/index.csv"
update_file "$new" "$main" "$uuid" "props/filepath/index.csv"
update_file "$new" "$main" "$uuid" "props/filesize/index.csv"
update_file "$new" "$main" "$uuid" "props/filetype/index.csv"
update_file "$new" "$main" "$uuid" "props/filepath/index.csv"
update_file "$new" "$main" "$uuid" "props/privacy/index.csv"
update_file "$new" "$main" "$uuid" "props/tag/index.csv"
#+end_src

** merge-gedcom.awk
#+begin_src awk :tangle scripts/merge-gedcom.awk

# merge-gedcom.awk
#
# Merge gedcom files
# structures must have _UID tags

function structures_old_push(uuid, head, xref, structure) {
    # if a structure doesn't have a uuid, generate one
    if (uuid == "") {
        uuidgen_cmd = "uuidgen"
        uuidgen_cmd | getline uuid_value
        uuid = uuid_value
        close(uuidgen_cmd)
    }
    structures_old[uuid][head]["xref"] = xref
    structures_old[uuid][head]["structure"] = structure
}
# structures_old
#   - {head}
#      - "structure"
#          - {structure}
#      - "xref"
#          - {xref}
function merge() {
    individuals = 1
    families = 1

    # for every uuid, map every xref to a new xref
    for (uuid in structures_old) {

        # set xref_old to match INDI or FAM
        for (head in structures_old[uuid]) {
            xref_old = structures_old[uuid][head]["xref"]
        }

        # create new xref
        if (match(xref_old, /I/)) {
            xref_new = "I" sprintf("%04i", individuals++)
        } else if (match(xref_old, /F/)) {
            xref_new = "F" sprintf("%04i", families++)
        }

        # map old xrefs to the new xref for renumbering
        for (head in structures_old[uuid]) {
            xref_old = structures_old[uuid][head]["xref"]
            # printf "set head: %s old: %s new: %s\n", head, xref_old, xref_new >> "/dev/stderr"
            xrefs[head][xref_old] = xref_new
        }
    }

    # for every uuid
    # get structure for every xref
    # renumber all xrefs inside
    # concatenate and deduplicate
    for (uuid in structures_old) {

        # build zerolevel line
        for (head in structures_old[uuid]) {
            xref_old = structures_old[uuid][head]["xref"]
            if (match(xref_old, /I/)) {
                xrefline = "0 @" xrefs[head][xref_old] "@" " INDI" RS
            } else if (match(xref_old, /F/)) {
                xrefline = "0 @" xrefs[head][xref_old] "@" " FAM" RS
            }
        }

        # renumber all xrefs in structures and concatenate
        structure_dup = ""
        for (head in structures_old[uuid]) {
            structure_old = structures_old[uuid][head]["structure"]

            # for every line in structure_old
            gsub(/\n$/, "", structure_old)
            split(structure_old, lines, RS)
            for (i in lines) {
                line = lines[i] RS

                # if the line is a substructure
                # and the superstructure was removed
                # remove the line
                if (delete_substructures) {
                    if (match(line, /^2/)) {
                        line = ""
                    } else {
                        # otherwise stop deleting substructures
                        delete_substructures = 0
                    }
                }
                # if a line has an xref
                if (match(line, /@.*@/)) {
                    # extract xref
                    xref_old = substr(line, RSTART, RLENGTH)
                    gsub(/@/, "", xref_old)
                    # find the new xref that maches the old xref
                    xref_new = xrefs[head][xref_old]
                    # printf "get head: %s old: %s new: %s\n", head, xref_to_renumber, xref_new >> "/dev/stderr"
                    # if no new xref found, delete the line
                    if (xref_new=="") {
                        line = ""
                        # remember to delete substructures
                        delete_substructures = 1
                    } else {
                        # otherwise replace old xref with a new one
                        gsub(xref_old, xref_new, line)
                    }
                }
                # append line to duplicated structure
                structure_dup = structure_dup line
            }
        }

        # printf "--dup-------\n" >> "/dev/stderr"
        # printf "%s", structure_dup >> "/dev/stderr"

        # deduplicate
        gsub(/\n$/, "", structure_dup)
        split(structure_dup, lines, RS)
        structure_uniq = ""
        delete seen
        for (i in lines) {
            line = lines[i]
            if (!seen[line]++) {
                structure_uniq = structure_uniq line RS
            }
        }

        # printf "--uniq------\n" >> "/dev/stderr"
        # printf "%s", structure_uniq >> "/dev/stderr"

        # build uuid line
        uuidline = "1 _UID " uuid RS

        printf "%s", xrefline structure_uniq uuidline
    }
}

BEGIN {
    printf "0 HEAD\n"
    printf "1 GEDC\n"
    printf "2 VERS 5.5.1\n"
    printf "2 FORM LINEAGE-LINKED\n"
    printf "1 CHAR UTF-8\n"
    printf "1 LANG Russian\n"
}
/^0 HEAD/ {
    head++
    next
}
/^0 TRLR/ {
    if (isStructure==1) {
        structures_old_push(uuid, head, xref, structure)
    }
    isStructure = 0
    next
}
/^0/ {
    if (isStructure==1) {
        structures_old_push(uuid, head, xref, structure)
    }
    # remember to save structure
    isStructure = 1
    # erase the last structure
    structure = ""
    uuid = ""
    xref = ""
    # read xref
    xref = match($0, /@.*@/)
    xref = substr($0, RSTART, RLENGTH)
    gsub(/@/, "", xref)

    next
}
/^1 _UID/ {
    # read uuid
    uuid = $0
    gsub(/^1 _UID /, "", uuid)

    next
}
{
    if (isStructure==1) {
        structure=structure $0 RS
    }
}
END {
    merge()
    printf "0 TRLR\n"
}
#+end_src
** adduuid.awk
#+begin_src awk :tangle scripts/adduuid.awk
BEGIN {}
/^0 .* INDI/ {
    "uuidgen" | getline uuid
    printf "%s\n1 _UID %s\n", $0, uuid
    close("uuidgen")
    next
}
/^0 .* FAM/ {
    "uuidgen" | getline uuid
    printf "%s\n1 _UID %s\n", $0, uuid
    close("uuidgen")
    next
}
{
    print
}
END {}
#+end_src
** break-ravdia.awk
#+begin_src awk :tangle scripts/break-ravdia.awk

# break-ravdia.awk
#
# Reads a biorg compilation,
# write each datum to a file
# output biorg with file metadata to stdout
# output path to temporary directory to stderr

function parse_property(line) {
    gsub("^:", "", line);
    st = index(line,":");
    prop_name = substr(line,1,st-1);
    prop_value = substr(line,st+1);
    # trim whitespace
    gsub("^[ \t]+", "", prop_value);
    gsub("[ \t]+$", "", prop_value);

    return prop_value
}
function write_node(temp, props, datum) {
    # generate uuid
    datum_uuid_cmd = "uuidgen | sha256sum | cut -c 1-64";
    datum_uuid_cmd | getline datum_uuid_new;
    datum_uuid = datum_uuid_new;
    close(datum_uuid_cmd);
    # write datum to temp/uuid.txt
    filepath = temp "/" datum_uuid;
    printf "%s\n", datum >> filepath;
    close(filepath);
    # get file size, type, moddate and hash
    filesize_cmd = "stat --printf \"%s\" " filepath;
    filesize_cmd | getline filesize;
    close(filesize_cmd);
    filetype_cmd = "file -b " filepath;
    filetype_cmd | getline filetype;
    close(filetype_cmd);
    filehash_cmd = "sha256sum " filepath " | cut -c 1-64";
    filehash_cmd | getline filehash;
    close(filehash_cmd);
    moddate_cmd = "stat --printf=\"%y\" " filepath " | cut -c 1-10";
    moddate_cmd | getline moddate;
    close(moddate_cmd);
    # add file_path to props
    filepath_prop = ":FILE_PATH: " filepath;
    filetype_prop = ":FILE_TYPE: " filetype;
    filesize_prop = ":FILE_SIZE: " filesize;
    filehash_prop = ":FILE_HASH: " filehash;
    moddate_prop = ":MOD_DATE: <" moddate ">";
    uuid_prop = ":UUID: " datum_uuid;
    props = props filepath_prop RS filetype_prop RS filesize_prop RS filehash_prop RS uuid_prop RS moddate_prop RS;
    # print new props without datum
    printf "%s\n", "* .\n:PROPERTIES:\n" props ":END:\n";
}
BEGIN {
    "mktemp -d" | getline temp;
    system(mkdir_cmd);
}
# heading line
/^\* \.$/ {
    afterheading=1
    # write previous node
    if (node==1) {
        write_node(temp, props, datum);
    }
    # remember to write node on the next heading
    node=1;
    # delete previous node's props and datum
    props="";
    datum="";
    next;
}
# remember to parse lines as properties
# while inside the property block
/^:PROPERTIES:/ {
    if (afterheading==1) {
        property_block=1; next;
    }
    afterheading=0;
}
/^:END:/ {
    afterheading=0;
    property_block=0; next;
}
/^:/ {
    afterheading=0;
    if (property_block==1) {
        props = props $0 RS;
        next;
    }
}
{
    afterheading=0;
    datum=datum $0 RS;
}
END {
    # write last node
    if (node==1) {
        write_node(temp, props, datum);
    }
    printf "%s\n", temp >> "/dev/stderr"
}
#+end_src
** init-metadir
#+begin_src sh :tangle scripts/init-metadir :tangle-mode (identity #o755)
mkdir -p metadir/pairs metadir/props/{tag,date,datum,filesize,filetype,name,rulepath}
#+end_src
** mdirsync
#+begin_src sh :tangle scripts/mdirsync :tangle-mode (identity #o755)
#!/bin/bash

usage() {
  printf 1>&2 "%s\n" "Usage: $0 INBOX [-c CONFIG] [-d METADIR]

  Syncs METADIR with INBOX biorg file

  OPTIONS:
  -c json file which contains the schema of properties and relations between them
     defaults to \$PWD/metadir.json
  -d folder which contains the index of properties and relations between them
     defaults to \$PWD/metadir

  EXAMPLE:
    $0 -d ./metadir -c ./metadir.json ./inbox.bi.org "
}

OPTIND=1
while getopts 'c:d:' opt; do
  case $opt in
    c) config="$OPTARG" ;;
    d) metadir="$OPTARG" ;;
    ,*) usage
       exit 1
  esac
done
shift "$(( OPTIND - 1 ))"

if [ $# -lt 1 ]; then
  usage
  exit 3
fi

inbox="$1"

# get the path to the folder which contains
# the index of properties and relations between them
if [ ! "$metadir" ]; then
    metadir="$PWD/metadir"
fi

# check if metadir exists
if [[ ! -d "$metadir" ]]; then
  printf 1>&2 "No metadir at %s\n" "$metadir"
  exit 3
fi

# get the path to the json file which contains
# the schema of properties and relations between them
if [ ! "$config" ]; then
    config="$PWD/metadir.json"
fi

# check if config exists
if [[ ! -f "$config" ]]; then
  printf 1>&2 "No config at %s\n" "$config"
  exit 3
fi

# locate other scripts
SCRIPTS="${BASH_SOURCE%/*}"
if [[ ! -d "$SCRIPTS" ]]; then SCRIPTS="$PWD"; fi

# break biorg
new=$(cat "$inbox" | awk -f $SCRIPTS/break-biorg.awk -v CONFIG="$config")
printf 2>&1 "%s\n" "$new"
# merge metadir
bash $SCRIPTS/merge -c "$config" "$new" "$metadir"
# backup biorg
bk=$(mktemp)
cp "$inbox" "$bk"
ln -sf "$bk" sync-bk
# rebuild biorg
bash $SCRIPTS/build-biorg -d "$new" -c "$config" > "$inbox"
#+end_src
* tests
** lookup
#+begin_src sh :tangle tests/test_lookup :tangle-mode (identity #o755)
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/lookup"
uuid1="8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704"
value1="value1"
tests_index=$(mktemp)

code() {
    printf "%s,%s" "$uuid1" "$value1" > $tests_index
}

test_lookup_fails_without_args() {
    assert_fail $script
}
test_lookup_fails_with_one_arg() {
    assert_fail $script $(mktemp)
}
test_lookup_succeeds_with_two_args() {
    code
    assert "$script $tests_index $uuid1"
}
test_lookup_prints_value() {
    code
    assert_equals "$value1" $($script $tests_index $uuid1) "should equal value1"
}
#+end_src

** unescape
#+begin_src sh :tangle tests/test_unescape :tangle-mode (identity #o755)
# what mock text?
# fails with wrong locale
# succeeds with right locale
#+end_src
** config
#+begin_src json :tangle tests/config.json
{
    "datum": {
        "type": "string"
    },
    "hostdate": {
        "parent": "datum",
        "dir": "date",
        "type": "date",
        "label": "HOST_DATE"
    },
    "hostname": {
        "parent": "datum",
        "dir": "name",
        "label": "HOST_NAME"
    },
    "guestdate": {
        "parent": "datum",
        "dir": "date",
        "type": "date",
        "label": "GUEST_DATE"
    },
    "guestname": {
        "parent": "datum",
        "dir": "name",
        "label": "GUEST_NAME"
    },
    "tag": {
        "parent": "datum",
        "label": "TAG"
    },
    "filepath": {
        "parent": "datum",
        "label": "FILE_PATH",
        "type": "string"
    },
    "moddate": {
        "parent": "filepath",
        "dir": "date",
        "type": "date",
        "label": "GUEST_DATE"
    },
    "filetype": {
        "parent": "filepath",
        "label": "FILE_TYPE",
        "type": "string"
    },
    "filesize": {
        "parent": "filepath",
        "label": "FILE_SIZE"
    },
    "filehash": {
        "parent": "filepath",
        "label": "FILE_HASH",
        "type": "hash"
    }
}
#+end_src

** build-prop
#+begin_src sh :tangle tests/test_build-prop :tangle-mode (identity #o755)
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/build-biorg"
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"

setup_metadir() {
    metadir=$(mktemp -d)
    export metadir
    mkdir -p $metadir/pairs $metadir/props/{tag,date,datum,filepath,filesize,filetype,name,rulepath}
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"value2\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    datum_index > "$metadir/props/datum/index.csv"
    fake date_index << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    date_index > "$metadir/props/date/index.csv"
    fake hostdate_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
EOF
    hostdate_pair > "$metadir/pairs/datum-hostdate.csv"
}
setup() {
    setup_metadir
    # source functions and redirect the rest to null
    source $script -d "$metadir" -c "$config" &>/dev/null
}

test_build-prop_succeeds() {
    assert "build_prop \"datum\" \"\" \"8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704\""
}
test_build-node_stderr() {
    build_prop "datum" "" "8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704" 2>&1 >/dev/null
    assert true
}
test_build-prop_returns_datum() {
    assert_equals "value1" "$(build_prop "datum" "" "8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704")"
}
test_build-prop_returns_hostdate() {
    assert_equals ":HOST_DATE: <2001-01-01>" "$(build_prop "hostdate" "datum" "8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704")"
}
#+end_src
** build-node
#+begin_src sh :tangle tests/test_build-node :tangle-mode (identity #o755)
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/build-biorg"
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"

setup_metadir() {
    metadir=$(mktemp -d)
    export metadir
    mkdir -p $metadir/pairs $metadir/props/{tag,date,datum,filesize,filetype,name,rulepath}
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"value2\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    datum_index > "$metadir/props/datum/index.csv"
    fake date_index << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    date_index > "$metadir/props/date/index.csv"
    fake hostdate_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
EOF
    hostdate_pair > "$metadir/pairs/datum-hostdate.csv"
}
setup() {
    setup_metadir
    # source functions and redirect the rest to null
    source $script -d "$metadir" -c "$config" &>/dev/null;
}

test_build-node_succeeds() {
    assert "build_node \"8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704\" &>/dev/null"
}
test_build-node_stderr() {
    build_node "8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704" "1" 2>&1 >/dev/null
    assert true
}
test_build-node_returns_node() {
    # export that variables that build_node expects in global scope
    config_props=$(jq -r 'keys | join(" ")' "$config")
    root=$(jq -r 'map_values(select(has("parent") | not)) | keys[0]' "$config")
    export config_props root
    fake mock << EOF
,* .
:PROPERTIES:
:UUID: 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704
:HOST_DATE: <2001-01-01>
:END:
value1
EOF
    assert_equals "$(mock)" "$(build_node "8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704" 2>/dev/null)"
}
#+end_src
** build-biorg
#+begin_src sh :tangle tests/test_build-biorg :tangle-mode (identity #o755)
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/build-biorg"
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"
uuid1="8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704"
value1="value1"
uuid2="0bb6648436e480468413313bce468453d5657fb9f8aa4b6e98c719b83415b0ae"
value2="value2"

setup_metadir() {
    metadir=$(mktemp -d)
    export metadir
    mkdir -p $metadir/pairs $metadir/props/{tag,date,datum,filesize,filetype,name,rulepath}
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"value2\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    datum_index > "$metadir/props/datum/index.csv"
    fake date_index << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    date_index > "$metadir/props/date/index.csv"
    fake hostdate_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
EOF
    hostdate_pair > "$metadir/pairs/datum-hostdate.csv"
}
setup() {
    setup_metadir
}

# test_build-biorg_fails_when_no_metadir() {}
test_build-biorg_succeeds() {
    assert "bash $script -d $metadir -c $config 2>/dev/null"
}
test_build-biorg_returns_nodes() {
    fake mock << EOF
,* .
:PROPERTIES:
:UUID: 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704
:HOST_DATE: <2001-01-01>
:END:
value1
,* .
:PROPERTIES:
:UUID: b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e
:HOST_DATE: <2002-01-01>
:END:
value2
,* .
:PROPERTIES:
:UUID: f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265
:HOST_DATE: <2003-01-01>
:END:
EOF
    assert_equals "$(mock)" "$(bash $script -d $metadir -c $config 2>/dev/null)"
}
#+end_src
** break-biorg.awk
#+begin_src sh :tangle tests/test_break-biorg-awk :tangle-mode (identity #o755)
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/break-biorg.awk"
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"

setup() {
    biorg=$(mktemp)
    export biorg
    fake biorg << EOF
,* .
:PROPERTIES:
:UUID: 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704
:HOST_DATE: <2001-01-01>
:FILE_PATH: "path/to/1"
:FILE_HASH: 7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
:TAG: tag
:END:
value1
,* .
:PROPERTIES:
:HOST_DATE: <2002-01-01>
:FILE_PATH: "path/to/2"
:FILE_HASH: 023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
:TAG: tag
:END:
value2
,* .
:PROPERTIES:
:HOST_DATE: <2003-01-01>
:TAG: tag
:END:
EOF
    biorg >> $biorg

    printf "0" > "/tmp/counter"
    _uuidgen() {
        if [ $(cat "/tmp/counter") == "0" ]; then
            printf "1A73DBDA-85E0-404A-9104-735602EF5F74\n"
            # b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e
            printf "1" > "/tmp/counter"
        else
            printf "3C128750-4D98-4A28-AFCD-0BDDAA77C632\n"
            # f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265
        fi
    }
    export -f _uuidgen
}

test_break-biorg-awk_succeeds() {
    assert "awk -f $script -v CONFIG=$config $biorg &>/dev/null"
}
test_break-biorg-awk_prints() {
    testdir=$(mktemp -d)
    fake mktemp <<< "$testdir"
    assert_equals "$testdir" "$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)"
}
test_break-biorg-awk_stderr() {
    awk -f $script -v CONFIG=$config $biorg 2>&1 >/dev/null
    assert true
}
test_break-biorg-awk_fails_without_config() {
    assert_fails "awk -f $script $biorg 2>/dev/null"
}
test_break-biorg-awk_writes_datum_index() {
    fake uuidgen _uuidgen
    testdir=$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)
    fake mock << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"value2\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    assert_equals "$(mock)" "$(cat $testdir/props/datum/index.csv)"
}
test_break-biorg-awk_writes_date_index() {
    testdir=$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)
    fake mock << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    assert_equals "$(mock)" "$(cat $testdir/props/date/index.csv)"
}
test_break-biorg-awk_writes_hostdate_pair() {
    fake uuidgen _uuidgen
    testdir=$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)
    fake mock << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
EOF
    assert_equals "$(mock)" "$(cat $testdir/pairs/datum-hostdate.csv)"
}
test_break-biorg-awk_writes_tag_index() {
    testdir=$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)
    fake mock << EOF
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
EOF
    assert_equals "$(mock)" "$(cat $testdir/props/tag/index.csv)"
}
test_break-biorg-awk_writes_tag_pair() {
    fake uuidgen _uuidgen
    testdir=$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)
    fake mock << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
EOF
    assert_equals "$(mock)" "$(cat $testdir/pairs/datum-tag.csv)"
}
test_break-biorg-awk_does_not_write_filehash_index() {
    testdir=$(awk -f $script -v CONFIG=$config $biorg)
    assert_fail "test -d $testdir/props/filehash"
}
test_break-biorg-awk_writes_filehash_pair() {
    fake uuidgen _uuidgen
    testdir=$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)
    fake mock << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
EOF
    assert_equals "$(mock)" "$(cat $testdir/pairs/filepath-filehash.csv)"
}
test_break-biorg-awk_writes_filepath_index() {
    testdir=$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)
    fake mock << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,\"path/to/2\"
EOF
    assert_equals "$(mock)" "$(cat $testdir/props/filepath/index.csv)"
}
test_break-biorg-awk_writes_filepath_pair() {
    fake uuidgen _uuidgen
    testdir=$(awk -f $script -v CONFIG=$config $biorg 2>/dev/null)
    fake mock << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865
EOF
    assert_equals "$(mock)" "$(cat $testdir/pairs/datum-filepath.csv)"
}
#+end_src

** break-biorg
#+begin_src sh
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/break-biorg"
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"

setup() {
    biorg=$(mktemp)
    export biorg
    fake biorg << EOF
,* .
:PROPERTIES:
:UUID: 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704
:HOST_DATE: <2001-01-01>
:FILE_PATH: "path/to/1"
:FILE_HASH: 7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
:TAG: tag
:END:
value1
,* .
:PROPERTIES:
:HOST_DATE: <2002-01-01>
:FILE_PATH: "path/to/2"
:FILE_HASH: 023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
:TAG: tag
:END:
value2
,* .
:PROPERTIES:
:HOST_DATE: <2003-01-01>
:TAG: tag
:END:
EOF
    biorg >> $biorg

    _uuidgen() {
        case "$PARALLEL_SEQ" in
            1) printf "1A73DBDA-85E0-404A-9104-735602EF5F74\n" ;;
            # b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e
            2) printf "3C128750-4D98-4A28-AFCD-0BDDAA77C632\n" ;;
            # f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265
            3) printf "8A896B3F-BC9D-4CBD-8F45-2C7F2BB5E2CF\n" ;;
            # cf65e28e5f1b0e0fd7b82a12000cf8792366d4a0a8efcf891b26b5493ec36312
            *) printf "5C23902C-CD54-4357-9932-79EBDFF86911\n" ;;
            # 870468c739be1e31ce0861cbde0f2144a0e2b5ff046556aadcaf7f991c01905a
        esac
    }
    export -f _uuidgen
}
test_break-biorg_succeeds() {
    assert "$script -c $config $biorg &>/dev/null"
}
test_break-biorg_prints() {
    testdir=$(mktemp -d)
    fake mktemp <<< "$testdir"
    assert_equals "$testdir" "$($script -c $config $biorg 2>/dev/null)"
}
test_break-biorg_stderr() {
    $script -c $config $biorg 2>&1 >/dev/null
    assert true
}
test_break-biorg_fails_without_config() {
    assert_fails "$script $biorg 2>/dev/null"
}
test_break-biorg_writes_datum_index() {
    fake uuidgen _uuidgen
    testdir=$($script -c $config $biorg 2>/dev/null)
    fake mock << EOF
cf65e28e5f1b0e0fd7b82a12000cf8792366d4a0a8efcf891b26b5493ec36312,\"\"
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"value2\"
EOF
    assert_equals "$(mock)" "$(cat $testdir/props/datum/index.csv | sort -t "," -k 2 -k 1)"
}
test_break-biorg_writes_date_index() {
    testdir=$($script -c $config $biorg 2>/dev/null)
    fake mock << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    assert_equals "$(mock)" "$(cat $testdir/props/date/index.csv | sort -t "," -k 2 -k 1)"
}
test_break-biorg_writes_hostdate_pair() {
    fake uuidgen _uuidgen
    testdir=$($script -c $config $biorg 2>/dev/null)
    fake mock << EOF
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
cf65e28e5f1b0e0fd7b82a12000cf8792366d4a0a8efcf891b26b5493ec36312,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
EOF
    assert_equals "$(mock)" "$(cat $testdir/pairs/datum-hostdate.csv | sort -t "," -k 2 -k 1)"
}
test_break-biorg_writes_tag_index() {
    testdir=$($script -c $config $biorg 2>/dev/null)
    fake mock << EOF
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
EOF
    assert_equals "$(mock)" "$(cat $testdir/props/tag/index.csv | sort -t "," -k 2 -k 1)"
}
test_break-biorg_writes_tag_pair() {
    fake uuidgen _uuidgen
    testdir=$($script -c $config $biorg 2>/dev/null)
    fake mock << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
cf65e28e5f1b0e0fd7b82a12000cf8792366d4a0a8efcf891b26b5493ec36312,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
EOF
    assert_equals "$(mock)" "$(cat $testdir/pairs/datum-tag.csv | sort -t "," -k 2 -k 1)"
}
test_break-biorg_does_not_write_filehash_index() {
    testdir=$($script -c $config $biorg)
    assert_fail "test -d $testdir/props/filehash"
}
test_break-biorg_writes_filehash_pair() {
    fake uuidgen _uuidgen
    testdir=$($script -c $config $biorg 2>/dev/null)
    fake mock << EOF
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
EOF
    assert_equals "$(mock)" "$(cat $testdir/pairs/filepath-filehash.csv | sort -t "," -k 2 -k 1)"
}
test_break-biorg_writes_filepath_index() {
    testdir=$($script -c $config $biorg 2>/dev/null)
    fake mock << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,\"path/to/2\"
EOF
    assert_equals "$(mock)" "$(cat $testdir/props/filepath/index.csv | sort -t "," -k 2 -k 1)"
}
test_break-biorg_writes_filepath_pair() {
    fake uuidgen _uuidgen
    testdir=$($script -c $config $biorg 2>/dev/null)
    fake mock << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865
EOF
    assert_equals "$(mock)" "$(cat $testdir/pairs/datum-filepath.csv | sort -t "," -k 2 -k 1)"
}
#+end_src

** merge
#+begin_src sh :tangle tests/test_merge :tangle-mode (identity #o755)
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/merge -c $config"

setup_main() {
    maindir=$(mktemp -d)
    export maindir
    mkdir -p $maindir/pairs $maindir/props/{tag,date,datum,filepath,filesize,filetype,name,rulepath}
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"\"
EOF
    datum_index > "$maindir/props/datum/index.csv"
    fake date_index << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
495ac5d03abc7e2812998371d1c9d8f802f1995fe9ab2135a30578852add5c44,2000-01-01
EOF
    date_index > "$maindir/props/date/index.csv"
    fake hostdate_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,495ac5d03abc7e2812998371d1c9d8f802f1995fe9ab2135a30578852add5c44
EOF
    hostdate_pair > "$maindir/pairs/datum-hostdate.csv"
#     fake tag_index << EOF
# 2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
# EOF
#     tag_index > "$maindir/props/tag/index.csv"
#     fake tag_pair << EOF
# 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
# b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
# EOF
    # tag_pair > "$maindir/pairs/datum-tag.csv"
    fake filepath_index << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,\"path/to/2\"
EOF
    filepath_index > "$maindir/props/filepath/index.csv"
    fake filepath_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865
EOF
    filepath_pair > "$maindir/pairs/datum-filepath.csv"
    fake filehash_pair << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
EOF
    filehash_pair > "$maindir/pairs/filepath-filehash.csv"
}

setup_new() {
    newdir=$(mktemp -d)
    export newdir
    mkdir -p $newdir/pairs $newdir/props/{tag,date,datum,filepath,filesize,filetype,name,rulepath}
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"value2\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    datum_index > "$newdir/props/datum/index.csv"
    fake date_index << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    date_index > "$newdir/props/date/index.csv"
    fake hostdate_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
EOF
    hostdate_pair > "$newdir/pairs/datum-hostdate.csv"
    fake tag_index << EOF
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
EOF
    tag_index > "$newdir/props/tag/index.csv"
    fake tag_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
EOF
    tag_pair > "$newdir/pairs/datum-tag.csv"
    fake filepath_index << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,\"path/to/2\"
1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05,\"path/to/3\"
EOF
    filepath_index > "$newdir/props/filepath/index.csv"
    fake filepath_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05
EOF
    filepath_pair > "$newdir/pairs/datum-filepath.csv"
    fake filehash_pair << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05,530e0adbaf82e521276261947eccf1061294a017dfe7e7cad8fb84a703feafcc
EOF
    filehash_pair > "$newdir/pairs/filepath-filehash.csv"
}

# a subset of main to test no changes
setup_same() {
    samedir=$(mktemp -d)
    export samedir
    mkdir -p $samedir/pairs $samedir/props/{tag,date,datum,filepath,filesize,filetype,name,rulepath}
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    datum_index > "$samedir/props/datum/index.csv"
    fake date_index << EOF
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
EOF
    date_index > "$samedir/props/date/index.csv"
    fake hostdate_pair << EOF
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
EOF
    hostdate_pair > "$samedir/pairs/datum-hostdate.csv"
    fake tag_index << EOF
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
EOF
    tag_index > "$samedir/props/tag/index.csv"
    fake tag_pair << EOF
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
EOF
    tag_pair > "$samedir/pairs/datum-tag.csv"
    fake filepath_index << EOF
1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05,\"path/to/3\"
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
EOF
    filepath_index > "$samedir/props/filepath/index.csv"
    fake filepath_pair << EOF
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
EOF
    filepath_pair > "$samedir/pairs/datum-filepath.csv"
    fake filehash_pair << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05,530e0adbaf82e521276261947eccf1061294a017dfe7e7cad8fb84a703feafcc
EOF
    filehash_pair > "$samedir/pairs/filepath-filehash.csv"
}

setup() {
    setup_main
    setup_new
    setup_same
}

test_merge_succeeds() {
    assert "$script $newdir $maindir &>/dev/null"
}
test_merge_stderr() {
    $script $newdir $maindir 2>&1 >/dev/null
    assert true
}
test_merge_datum_index_edits() {
    updated_value='b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,"value2"'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$updated_value' $maindir/props/datum/index.csv 2>&1"
}
test_merge_datum_index_adds() {
    new_value='f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,""'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$new_value' $maindir/props/datum/index.csv 2>&1"
}
test_merge_date_index_edits() {
    updated_value='161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$updated_value' $maindir/props/date/index.csv 2>&1"
}
test_merge_date_index_adds() {
    new_value='28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$new_value' $maindir/props/date/index.csv 2>&1"
}
test_merge_hostdate_pair_edits() {
    updated_value='b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$updated_value' $maindir/pairs/datum-hostdate.csv 2>&1"
}
test_merge_hostdate_pair_adds() {
    new_value='f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$new_value' $maindir/pairs/datum-hostdate.csv 2>&1"
}
test_merge_tag_index_is_created() {

    fake tag_index << EOF
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
EOF
    $script $newdir $maindir &>/dev/null
    assert_equals $(tag_index) "$(cat $maindir/props/tag/index.csv)"
}
test_merge_tag_pair_adds() {
    new_value='f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$new_value' $maindir/pairs/datum-tag.csv 2>&1"
}
test_merge_filepath_index_adds() {
    new_value='1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05,\"path/to/3\"'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$new_value' $maindir/props/filepath/index.csv 2>&1"
}
test_merge_filepath_pair_edits() {
    updated_value='b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$updated_value' $maindir/pairs/datum-filepath.csv 2>&1"
}
test_merge_filehash_pair_adds() {
    new_value='1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05,530e0adbaf82e521276261947eccf1061294a017dfe7e7cad8fb84a703feafcc'
    $script $newdir $maindir &>/dev/null
    assert "grep -o '$new_value' $maindir/pairs/filepath-filehash.csv 2>&1"
}
test_merge_datum_does_not_change() {
    value="8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"value2\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\""

    $script $samedir $newdir &>/dev/null
    assert_equals "$value" "$(cat $newdir/props/datum/index.csv)"
}
test_merge_date_does_not_change() {
    value="8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"value2\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\""

    $script $samedir $newdir &>/dev/null
    assert_equals "$value" "$(cat $newdir/props/datum/index.csv)"
}
#+end_src

** mdirsync
#+begin_src sh :tangle tests/test_sync :tangle-mode (identity #o755)
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/mdirsync"

setup_old() {
    old=$(mktemp)
    export old
    fake old << EOF
,* .
:PROPERTIES:
:UUID: 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704
:HOST_DATE: <2001-01-01>
:FILE_PATH: "path/to/1"
:FILE_HASH: 7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
:TAG: tag
:END:
value1
,* .
:PROPERTIES:
:HOST_DATE: <2002-01-01>
:FILE_PATH: "path/to/2"
:FILE_HASH: 023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
:TAG: tag
:END:
value2
,* .
:PROPERTIES:
:HOST_DATE: <2003-01-01>
:TAG: tag
:END:
EOF
    old >> $old
}
setup_new() {
    new=$(mktemp)
    export new
    fake new << EOF
,* .
:PROPERTIES:
:UUID: 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704
:TAG: tag
:HOST_DATE: <2001-01-01>
:FILE_PATH: "path/to/1"
:FILE_HASH: 7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
:END:
value1
,* .
:PROPERTIES:
:UUID: b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e
:TAG: tag
:HOST_DATE: <2002-01-01>
:FILE_PATH: "path/to/2"
:FILE_HASH: 023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
:END:
value2
,* .
:PROPERTIES:
:UUID: f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265
:TAG: tag
:HOST_DATE: <2003-01-01>
:END:
EOF
    new >> $new
}

setup() {
    metadir=$(mktemp -d)
    export metadir
    mkdir -p $metadir/pairs $metadir/props/{tag,date,datum,filepath,filesize,filetype,name,rulepath}

    setup_old
    setup_new

    printf "0" > "/tmp/counter"
    _uuidgen() {
        if [ $(cat "/tmp/counter") == "0" ]; then
            printf "1A73DBDA-85E0-404A-9104-735602EF5F74\n"
            # b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e
            printf "1" > "/tmp/counter"
        else
            printf "3C128750-4D98-4A28-AFCD-0BDDAA77C632\n"
            # f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265
        fi
    }
    export -f _uuidgen
}
test_sync_succeeds() {
    assert "$script -c $config -d $metadir $old &>/dev/null"
}
test_sync_stderr() {
    $script -c $config -d $metadir $old 2>&1 >/dev/null
    assert true
}
test_sync_populates_datum_index() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,\"value2\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/props/datum/index.csv)"
}
test_sync_populates_date_index() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/props/date/index.csv)"
}
test_sync_populates_hostdate_pair() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/pairs/datum-hostdate.csv)"
}
test_sync_populates_filepath_index() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,\"path/to/2\"
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/props/filepath/index.csv)"
}
test_sync_populates_filepath_pair() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/pairs/datum-filepath.csv)"
}
test_sync_populates_filehash_pair() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/pairs/filepath-filehash.csv)"
}
test_sync_syncs_uuids() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    assert_equals "$(cat $new)" "$(cat $old)"
}
# test_sync_syncs_cyrillics() {}
#+end_src

** mdirsync-parallel
#+begin_src sh
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/mdirsync"

setup_old() {
    old=$(mktemp)
    export old
    fake old << EOF
,* .
:PROPERTIES:
:UUID: 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704
:HOST_DATE: <2001-01-01>
:FILE_PATH: "path/to/1"
:FILE_HASH: 7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
:TAG: tag
:END:
value1
,* .
:PROPERTIES:
:HOST_DATE: <2002-01-01>
:FILE_PATH: "path/to/2"
:FILE_HASH: 023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
:TAG: tag
:END:
value2
,* .
:PROPERTIES:
:HOST_DATE: <2003-01-01>
:TAG: tag
:END:
EOF
    old >> $old
}
setup_new() {
    new=$(mktemp)
    export new
    fake new << EOF
,* .
:PROPERTIES:
:UUID: cf65e28e5f1b0e0fd7b82a12000cf8792366d4a0a8efcf891b26b5493ec36312
:TAG: tag
:HOST_DATE: <2003-01-01>
:END:

,* .
:PROPERTIES:
:UUID: 8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704
:TAG: tag
:HOST_DATE: <2001-01-01>
:FILE_PATH: path/to/1
:FILE_HASH: 7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
:END:
value1
,* .
:PROPERTIES:
:UUID: f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265
:TAG: tag
:HOST_DATE: <2002-01-01>
:FILE_PATH: path/to/2
:FILE_HASH: 023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
:END:
value2
EOF
    new >> $new
}

setup() {
    metadir=$(mktemp -d)
    export metadir
    mkdir -p $metadir/pairs $metadir/props/{tag,date,datum,filepath,filesize,filetype,name,rulepath}

    setup_old
    setup_new

    _uuidgen() {
        case "$PARALLEL_SEQ" in
            1) printf "1A73DBDA-85E0-404A-9104-735602EF5F74\n" ;;
            # b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e
            2) printf "3C128750-4D98-4A28-AFCD-0BDDAA77C632\n" ;;
            # f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265
            3) printf "8A896B3F-BC9D-4CBD-8F45-2C7F2BB5E2CF\n" ;;
            # cf65e28e5f1b0e0fd7b82a12000cf8792366d4a0a8efcf891b26b5493ec36312
            *) printf "5C23902C-CD54-4357-9932-79EBDFF86911\n" ;;
            # 870468c739be1e31ce0861cbde0f2144a0e2b5ff046556aadcaf7f991c01905a
        esac
    }
    export -f _uuidgen
}
test_sync_succeeds() {
    assert "$script -c $config -d $metadir $old &>/dev/null"
}
test_sync_stderr() {
    $script -c $config -d $metadir $old 2>&1 >/dev/null
    assert true
}
test_sync_populates_datum_index() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
cf65e28e5f1b0e0fd7b82a12000cf8792366d4a0a8efcf891b26b5493ec36312,\"\"
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"value2\"
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/props/datum/index.csv | sort -t "," -k 2 -k 1)"
}
test_sync_populates_date_index() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/props/date/index.csv | sort -t "," -k 2 -k 1)"
}
test_sync_populates_hostdate_pair() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
cf65e28e5f1b0e0fd7b82a12000cf8792366d4a0a8efcf891b26b5493ec36312,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/pairs/datum-hostdate.csv | sort -t "," -k 2 -k 1)"
}
test_sync_populates_filepath_index() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,\"path/to/2\"
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/props/filepath/index.csv | sort -t "," -k 2 -k 1)"
}
test_sync_populates_filepath_pair() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/pairs/datum-filepath.csv | sort -t "," -k 2 -k 1)"
}
test_sync_populates_filehash_pair() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    fake datum_index << EOF
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
EOF
    assert_equals "$(datum_index)" "$(cat $metadir/pairs/filepath-filehash.csv | sort -t "," -k 2 -k 1)"
}
test_sync_syncs_uuids() {
    fake uuidgen _uuidgen
    $script -c $config -d $metadir $old &>/dev/null
    assert_equals "$(cat $new)" "$(cat $old)"
}
# test_sync_syncs_cyrillics() {}
#+end_src

** gc
#+begin_src sh :tangle tests/test_gc :tangle-mode (identity #o755)
script="/Users/fetsorn/mm/0---codes/0-beams/scripts/gc"
config="/Users/fetsorn/mm/0---codes/0-beams/tests/config.json"

setup_old() {
    olddir=$(mktemp -d)
    export olddir
    mkdir -p $olddir/pairs $olddir/props/{tag,date,datum,filepath,filesize,filetype,name,rulepath}
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    datum_index > "$olddir/props/datum/index.csv"
    fake date_index << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc,2002-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    date_index > "$olddir/props/date/index.csv"
    fake hostdate_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,161c6b3d37ba3341b7775b10730b2ded837c3d84d77fb1a046fa198e9db8cbbc
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
EOF
    hostdate_pair > "$olddir/pairs/datum-hostdate.csv"
    fake tag_index << EOF
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
EOF
    tag_index > "$olddir/props/tag/index.csv"
    fake tag_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
EOF
    tag_pair > "$olddir/pairs/datum-tag.csv"
    fake filepath_index << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,\"path/to/2\"
1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05,\"path/to/3\"
EOF
    filepath_index > "$olddir/props/filepath/index.csv"
    fake filepath_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05
EOF
    filepath_pair > "$olddir/pairs/datum-filepath.csv"
    fake filehash_pair << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
1e8251d0c0cfed1944735156e09c934976ece0bf6b89f75e0ba16f372ec9aa05,530e0adbaf82e521276261947eccf1061294a017dfe7e7cad8fb84a703feafcc
EOF
    filehash_pair > "$olddir/pairs/filepath-filehash.csv"
}

setup_new() {
    newdir=$(mktemp -d)
    export newdir
    mkdir -p $newdir/pairs $newdir/props/{tag,date,datum,filepath,filesize,filetype,name,rulepath}
    fake datum_index << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,\"value1\"
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,\"\"
EOF
    datum_index > "$newdir/props/datum/index.csv"
    fake date_index << EOF
4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d,2001-01-01
28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10,2003-01-01
EOF
    date_index > "$newdir/props/date/index.csv"
    fake hostdate_pair << EOF
f35d45c3ee3e68cf9e36ee10df3edb02104c22b2d47ab17e64114ffb9c208265,28a15dd418a2eed8bc7c2133b21bf942182cc58160dfea0c9dd98f155d80ea10
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,4935b73812dd87780ee8deae03d0bbcb125bbcdc05271066ca527ab029e4e79d
EOF
    hostdate_pair > "$newdir/pairs/datum-hostdate.csv"
    fake tag_index << EOF
2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c,tag
EOF
    tag_index > "$newdir/props/tag/index.csv"
    fake tag_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
b52dc2b8884fc396c108c095da157d8607ee7d61a1e6b4b501b660d42f93c58e,2a1073a6e67f0e5f09a5957c659503c690efe7272be8313df872556a9a684d8c
EOF
    tag_pair > "$newdir/pairs/datum-tag.csv"
    fake filepath_index << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,\"path/to/1\"
EOF
    filepath_index > "$newdir/props/filepath/index.csv"
    fake filepath_pair << EOF
8260502525153a8775ecb052f41e4e908aba4c94b07ef90263fff77195392704,01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee
EOF
    filepath_pair > "$newdir/pairs/datum-filepath.csv"
    fake filehash_pair << EOF
01f8dafeb2559c983006156763f9c3b951b64688b3b41a9e5ad7cb695110e8ee,7346896c0ac9b7404de14c7402ed06c1892d7429f24c69e8f0f7bcec6440b7ef
424bd3271c0c940304ec6e9f4412a422735caeeb9638038bf509e36ae5d4f865,023b9dfa450e761b1a4ffcf9dd34a2fde273d78c5914957dfe39153aaca8a629
EOF
    filehash_pair > "$newdir/pairs/filepath-filehash.csv"
}

setup() {
    setup_old
    setup_new
}

test_gc_succeeds() {
    assert "bash $script -c $config -d $olddir &>/dev/null"
}
test_gc_stderr() {
    bash $script -c $config -d $olddir 2>&1 >/dev/null
    assert true
}
test_gc_removes_hostdate_pair() {
    bash $script -c $config -d $olddir &>/dev/null
    assert_equals "$(cat $newdir/pairs/datum-hostdate.csv)" "$(cat $olddir/pairs/datum-hostdate.csv)"
}
test_gc_removes_hostdate_index() {
    bash $script -c $config -d $olddir &>/dev/null
    assert_equals "$(cat $newdir/props/date/index.csv)" "$(cat $olddir/props/date/index.csv)"
}
test_gc_removes_filepath_pair() {
    bash $script -c $config -d $olddir &>/dev/null
    assert_equals "$(cat $newdir/pairs/datum-filepath.csv)" "$(cat $olddir/pairs/datum-filepath.csv)"
}
test_gc_removes_filepath_index() {
    bash $script -c $config -d $olddir &>/dev/null
    assert_equals "$(cat $newdir/props/filepath/index.csv)" "$(cat $olddir/props/filepath/index.csv)"
}
#+end_src
